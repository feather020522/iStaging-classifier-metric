Traceback (most recent call last):
  File "/home/tingwei/zillow_data/classifier_resnet50.py", line 413, in <module>
    net.cuda()          # train on GPU
AttributeError: 'list' object has no attribute 'cuda'
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/classifier_resnet50.py", line 413, in <module>
    net.cuda()          # train on GPU
AttributeError: 'str' object has no attribute 'cuda'
alpha set
parameters: 
batch_size = 64
shuffle_train = True
num_workers = 8
epoch = 50
augmentation = numpy.roll + colorJitter
Start training, 2023-06-26 18:41:57.383414
epoch # 1 done, 2023-06-26 18:47:34.856432
epoch # 2 done, 2023-06-26 18:52:47.993994
val # 2 done, 2023-06-26 18:57:41.296966
epoch # 3 done, 2023-06-26 19:02:51.761996
epoch # 4 done, 2023-06-26 19:08:01.997793
val # 4 done, 2023-06-26 19:12:55.471353
epoch # 5 done, 2023-06-26 19:18:06.281960
epoch # 6 done, 2023-06-26 19:23:18.391252
val # 6 done, 2023-06-26 19:28:13.428134
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/classifier_resnet50.py", line 463, in <module>
    loss = criterion(outputs, labels)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/tingwei/zillow_data/focal_loss.py", line 68, in forward
    if len(y) == 0:
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/_tensor.py", line 701, in __len__
    def __len__(self):
KeyboardInterrupt
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 8
epoch = 20

Start training, 2023-07-06 04:41:40.617522
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 219, in <module>
    inputs, labels = data[0].cuda(), data[1].cuda()
AttributeError: 'list' object has no attribute 'cuda'
alpha set
parameters: 
batch_size = 64
shuffle_train = True
num_workers = 8
epoch = 50
augmentation = numpy.roll + colorJitter
Start training, 2023-07-06 04:44:27.239393

Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 219, in <module>
    inputs, labels = data[0].cuda(), data[1].cuda()
AttributeError: 'list' object has no attribute 'cuda'
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 8
epoch = 20

Start training, 2023-07-06 04:47:17.516015
[tensor([[[[0.4784, 0.4784, 0.4824,  ..., 0.4824, 0.4824, 0.4824],
          [0.4784, 0.4784, 0.4824,  ..., 0.4824, 0.4824, 0.4784],
          [0.4784, 0.4784, 0.4784,  ..., 0.4784, 0.4784, 0.4784],
          ...,
          [0.4510, 0.4353, 0.4275,  ..., 0.4471, 0.4549, 0.4588],
          [0.4471, 0.4431, 0.4392,  ..., 0.4392, 0.4471, 0.4471],
          [0.4078, 0.4039, 0.4039,  ..., 0.4118, 0.4078, 0.4078]],

         [[0.4471, 0.4471, 0.4510,  ..., 0.4510, 0.4510, 0.4510],
          [0.4510, 0.4510, 0.4510,  ..., 0.4549, 0.4549, 0.4510],
          [0.4510, 0.4510, 0.4510,  ..., 0.4510, 0.4510, 0.4510],
          ...,
          [0.3569, 0.3412, 0.3333,  ..., 0.3608, 0.3686, 0.3725],
          [0.3608, 0.3608, 0.3529,  ..., 0.3569, 0.3608, 0.3608],
          [0.3412, 0.3373, 0.3412,  ..., 0.3412, 0.3451, 0.3412]],

         [[0.4353, 0.4392, 0.4392,  ..., 0.4392, 0.4392, 0.4392],
          [0.4353, 0.4353, 0.4353,  ..., 0.4353, 0.4353, 0.4314],
          [0.4275, 0.4275, 0.4275,  ..., 0.4275, 0.4275, 0.4275],
          ...,
          [0.3490, 0.3333, 0.3216,  ..., 0.3490, 0.3608, 0.3647],
          [0.3451, 0.3412, 0.3373,  ..., 0.3412, 0.3490, 0.3490],
          [0.3255, 0.3255, 0.3255,  ..., 0.3373, 0.3373, 0.3373]]]]), tensor([[[[0.4902, 0.4902, 0.4941,  ..., 0.4941, 0.4941, 0.4941],
          [0.4941, 0.4941, 0.4941,  ..., 0.4941, 0.4941, 0.4941],
          [0.4941, 0.4902, 0.4941,  ..., 0.4941, 0.4941, 0.4941],
          ...,
          [0.3843, 0.3804, 0.3686,  ..., 0.4039, 0.3961, 0.3882],
          [0.4000, 0.3961, 0.3882,  ..., 0.4039, 0.4000, 0.3961],
          [0.2941, 0.2902, 0.2902,  ..., 0.3020, 0.2941, 0.2941]],

         [[0.4745, 0.4745, 0.4784,  ..., 0.4784, 0.4784, 0.4784],
          [0.4784, 0.4784, 0.4784,  ..., 0.4784, 0.4784, 0.4784],
          [0.4784, 0.4745, 0.4784,  ..., 0.4784, 0.4784, 0.4784],
          ...,
          [0.3137, 0.3098, 0.2980,  ..., 0.3373, 0.3333, 0.3176],
          [0.3294, 0.3255, 0.3176,  ..., 0.3373, 0.3333, 0.3294],
          [0.2314, 0.2314, 0.2275,  ..., 0.2431, 0.2353, 0.2314]],

         [[0.4706, 0.4706, 0.4706,  ..., 0.4706, 0.4745, 0.4745],
          [0.4745, 0.4745, 0.4745,  ..., 0.4745, 0.4745, 0.4745],
          [0.4667, 0.4667, 0.4667,  ..., 0.4667, 0.4706, 0.4667],
          ...,
          [0.3137, 0.3137, 0.3020,  ..., 0.3373, 0.3333, 0.3255],
          [0.3373, 0.3333, 0.3216,  ..., 0.3412, 0.3373, 0.3373],
          [0.2471, 0.2471, 0.2471,  ..., 0.2627, 0.2588, 0.2549]]]]), tensor([[[[0.4745, 0.4745, 0.4784,  ..., 0.4784, 0.4784, 0.4745],
          [0.4706, 0.4745, 0.4784,  ..., 0.4706, 0.4745, 0.4706],
          [0.4667, 0.4706, 0.4706,  ..., 0.4706, 0.4745, 0.4706],
          ...,
          [0.4471, 0.4471, 0.4471,  ..., 0.4157, 0.4235, 0.4353],
          [0.4627, 0.4549, 0.4471,  ..., 0.4784, 0.4745, 0.4706],
          [0.1647, 0.1647, 0.1725,  ..., 0.1686, 0.1686, 0.1686]],

         [[0.4392, 0.4392, 0.4431,  ..., 0.4431, 0.4431, 0.4392],
          [0.4353, 0.4392, 0.4392,  ..., 0.4353, 0.4392, 0.4353],
          [0.4353, 0.4353, 0.4353,  ..., 0.4392, 0.4431, 0.4392],
          ...,
          [0.4275, 0.4275, 0.4275,  ..., 0.3882, 0.3961, 0.4078],
          [0.4275, 0.4157, 0.4118,  ..., 0.4471, 0.4353, 0.4314],
          [0.0941, 0.0941, 0.0980,  ..., 0.0980, 0.0980, 0.0980]],

         [[0.4431, 0.4431, 0.4471,  ..., 0.4471, 0.4471, 0.4431],
          [0.4392, 0.4431, 0.4471,  ..., 0.4392, 0.4431, 0.4392],
          [0.4392, 0.4392, 0.4392,  ..., 0.4431, 0.4431, 0.4392],
          ...,
          [0.4824, 0.4863, 0.4863,  ..., 0.4431, 0.4471, 0.4667],
          [0.4902, 0.4824, 0.4784,  ..., 0.5020, 0.4980, 0.4941],
          [0.2157, 0.2157, 0.2196,  ..., 0.2196, 0.2235, 0.2196]]]]), tensor([[[[0.4235, 0.4235, 0.4235,  ..., 0.4235, 0.4235, 0.4235],
          [0.4275, 0.4275, 0.4275,  ..., 0.4275, 0.4275, 0.4275],
          [0.4235, 0.4235, 0.4235,  ..., 0.4235, 0.4235, 0.4235],
          ...,
          [0.3529, 0.3529, 0.3608,  ..., 0.3843, 0.3647, 0.3569],
          [0.3686, 0.3647, 0.3647,  ..., 0.3804, 0.3765, 0.3725],
          [0.2431, 0.2431, 0.2431,  ..., 0.2588, 0.2510, 0.2471]],

         [[0.3961, 0.3961, 0.3961,  ..., 0.3961, 0.3961, 0.3961],
          [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],
          [0.3961, 0.3961, 0.3961,  ..., 0.3961, 0.3961, 0.3961],
          ...,
          [0.2667, 0.2667, 0.2667,  ..., 0.2902, 0.2706, 0.2667],
          [0.2824, 0.2824, 0.2824,  ..., 0.2863, 0.2784, 0.2824],
          [0.1765, 0.1765, 0.1765,  ..., 0.1922, 0.1843, 0.1804]],

         [[0.3647, 0.3647, 0.3647,  ..., 0.3647, 0.3647, 0.3647],
          [0.3686, 0.3686, 0.3686,  ..., 0.3686, 0.3647, 0.3647],
          [0.3608, 0.3608, 0.3569,  ..., 0.3569, 0.3608, 0.3569],
          ...,
          [0.2039, 0.2039, 0.2039,  ..., 0.2392, 0.2196, 0.2078],
          [0.2235, 0.2196, 0.2157,  ..., 0.2314, 0.2235, 0.2235],
          [0.1569, 0.1569, 0.1529,  ..., 0.1725, 0.1647, 0.1608]]]]), tensor([[[[0.5451, 0.5451, 0.5451,  ..., 0.5451, 0.5451, 0.5451],
          [0.5451, 0.5451, 0.5451,  ..., 0.5451, 0.5412, 0.5451],
          [0.5412, 0.5412, 0.5412,  ..., 0.5412, 0.5412, 0.5451],
          ...,
          [0.4431, 0.4431, 0.4431,  ..., 0.4392, 0.4392, 0.4471],
          [0.4235, 0.4235, 0.4235,  ..., 0.4157, 0.4157, 0.4196],
          [0.3843, 0.3843, 0.3882,  ..., 0.3882, 0.3843, 0.3843]],

         [[0.4667, 0.4667, 0.4667,  ..., 0.4667, 0.4667, 0.4667],
          [0.4667, 0.4667, 0.4667,  ..., 0.4667, 0.4627, 0.4667],
          [0.4627, 0.4627, 0.4627,  ..., 0.4627, 0.4627, 0.4667],
          ...,
          [0.2941, 0.2941, 0.2980,  ..., 0.2902, 0.2941, 0.3020],
          [0.2745, 0.2745, 0.2745,  ..., 0.2667, 0.2667, 0.2745],
          [0.2431, 0.2431, 0.2471,  ..., 0.2431, 0.2431, 0.2431]],

         [[0.2706, 0.2706, 0.2706,  ..., 0.2706, 0.2706, 0.2706],
          [0.2667, 0.2667, 0.2667,  ..., 0.2667, 0.2667, 0.2667],
          [0.2627, 0.2627, 0.2627,  ..., 0.2627, 0.2627, 0.2667],
          ...,
          [0.1020, 0.0941, 0.0941,  ..., 0.0863, 0.0902, 0.0980],
          [0.0745, 0.0706, 0.0706,  ..., 0.0627, 0.0627, 0.0706],
          [0.0471, 0.0471, 0.0510,  ..., 0.0471, 0.0471, 0.0471]]]]), tensor([[[[0.5569, 0.5569, 0.5608,  ..., 0.5569, 0.5608, 0.5608],
          [0.5569, 0.5569, 0.5569,  ..., 0.5529, 0.5569, 0.5569],
          [0.5569, 0.5529, 0.5569,  ..., 0.5529, 0.5529, 0.5490],
          ...,
          [0.5020, 0.5020, 0.4980,  ..., 0.4980, 0.4980, 0.4980],
          [0.4902, 0.4902, 0.4941,  ..., 0.4863, 0.4863, 0.4902],
          [0.2471, 0.2471, 0.2510,  ..., 0.2549, 0.2510, 0.2510]],

         [[0.4745, 0.4745, 0.4784,  ..., 0.4745, 0.4784, 0.4784],
          [0.4745, 0.4745, 0.4745,  ..., 0.4706, 0.4745, 0.4745],
          [0.4706, 0.4706, 0.4745,  ..., 0.4706, 0.4706, 0.4706],
          ...,
          [0.3569, 0.3569, 0.3529,  ..., 0.3529, 0.3529, 0.3529],
          [0.3451, 0.3451, 0.3412,  ..., 0.3412, 0.3412, 0.3451],
          [0.1373, 0.1373, 0.1373,  ..., 0.1412, 0.1373, 0.1373]],

         [[0.3059, 0.3059, 0.3098,  ..., 0.3059, 0.3098, 0.3098],
          [0.3059, 0.3059, 0.3059,  ..., 0.3020, 0.3020, 0.3020],
          [0.3020, 0.3020, 0.3059,  ..., 0.3020, 0.3020, 0.3020],
          ...,
          [0.1882, 0.1882, 0.1882,  ..., 0.1882, 0.1843, 0.1882],
          [0.1686, 0.1686, 0.1686,  ..., 0.1647, 0.1647, 0.1686],
          [0.0431, 0.0431, 0.0471,  ..., 0.0510, 0.0471, 0.0471]]]]), tensor([[[[0.4118, 0.4157, 0.4157,  ..., 0.4118, 0.4118, 0.4118],
          [0.3922, 0.3922, 0.3922,  ..., 0.3922, 0.3922, 0.3922],
          [0.3922, 0.3882, 0.3882,  ..., 0.3922, 0.3922, 0.3882],
          ...,
          [0.2941, 0.2902, 0.2902,  ..., 0.3176, 0.3020, 0.2941],
          [0.2863, 0.2824, 0.2863,  ..., 0.3059, 0.2980, 0.2902],
          [0.2510, 0.2510, 0.2510,  ..., 0.2510, 0.2510, 0.2510]],

         [[0.3333, 0.3333, 0.3373,  ..., 0.3373, 0.3333, 0.3333],
          [0.3059, 0.3059, 0.3059,  ..., 0.3098, 0.3059, 0.3059],
          [0.3059, 0.3059, 0.3098,  ..., 0.3059, 0.3059, 0.3020],
          ...,
          [0.2235, 0.2196, 0.2196,  ..., 0.2471, 0.2275, 0.2235],
          [0.2118, 0.2118, 0.2118,  ..., 0.2314, 0.2235, 0.2196],
          [0.1765, 0.1765, 0.1765,  ..., 0.1725, 0.1725, 0.1725]],

         [[0.2667, 0.2667, 0.2667,  ..., 0.2627, 0.2627, 0.2588],
          [0.2157, 0.2157, 0.2196,  ..., 0.2157, 0.2157, 0.2157],
          [0.2118, 0.2118, 0.2157,  ..., 0.2118, 0.2118, 0.2078],
          ...,
          [0.1451, 0.1451, 0.1451,  ..., 0.1843, 0.1608, 0.1529],
          [0.1490, 0.1490, 0.1451,  ..., 0.1725, 0.1647, 0.1608],
          [0.1176, 0.1176, 0.1176,  ..., 0.1137, 0.1137, 0.1137]]]]), tensor([[[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],
          [0.5020, 0.4980, 0.5020,  ..., 0.4980, 0.4980, 0.5020],
          [0.4902, 0.4941, 0.4941,  ..., 0.4941, 0.4941, 0.4941],
          ...,
          [0.5686, 0.5647, 0.5647,  ..., 0.5765, 0.5725, 0.5725],
          [0.5725, 0.5804, 0.5804,  ..., 0.5765, 0.5725, 0.5725],
          [0.4510, 0.4510, 0.4510,  ..., 0.4510, 0.4510, 0.4510]],

         [[0.4667, 0.4667, 0.4667,  ..., 0.4667, 0.4667, 0.4667],
          [0.4667, 0.4627, 0.4667,  ..., 0.4627, 0.4627, 0.4667],
          [0.4549, 0.4588, 0.4588,  ..., 0.4588, 0.4588, 0.4588],
          ...,
          [0.4431, 0.4392, 0.4353,  ..., 0.4549, 0.4510, 0.4471],
          [0.4392, 0.4392, 0.4392,  ..., 0.4392, 0.4392, 0.4353],
          [0.2980, 0.2941, 0.2980,  ..., 0.2980, 0.2980, 0.2980]],

         [[0.4431, 0.4431, 0.4431,  ..., 0.4431, 0.4431, 0.4431],
          [0.4471, 0.4431, 0.4471,  ..., 0.4471, 0.4471, 0.4471],
          [0.4275, 0.4314, 0.4314,  ..., 0.4353, 0.4353, 0.4353],
          ...,
          [0.3137, 0.3020, 0.2941,  ..., 0.3412, 0.3333, 0.3216],
          [0.2784, 0.2824, 0.2784,  ..., 0.2941, 0.2863, 0.2824],
          [0.1569, 0.1529, 0.1529,  ..., 0.1608, 0.1608, 0.1608]]]]), tensor([[[[0.5490, 0.5490, 0.5451,  ..., 0.5490, 0.5490, 0.5490],
          [0.5490, 0.5490, 0.5490,  ..., 0.5451, 0.5490, 0.5490],
          [0.5490, 0.5490, 0.5490,  ..., 0.5490, 0.5490, 0.5490],
          ...,
          [0.4039, 0.4078, 0.4039,  ..., 0.4000, 0.4000, 0.4039],
          [0.3765, 0.3765, 0.3804,  ..., 0.3804, 0.3804, 0.3804],
          [0.2353, 0.2353, 0.2353,  ..., 0.2431, 0.2392, 0.2353]],

         [[0.4627, 0.4627, 0.4627,  ..., 0.4667, 0.4667, 0.4667],
          [0.4627, 0.4667, 0.4667,  ..., 0.4627, 0.4667, 0.4667],
          [0.4667, 0.4667, 0.4667,  ..., 0.4667, 0.4667, 0.4667],
          ...,
          [0.3137, 0.3137, 0.3137,  ..., 0.3098, 0.3098, 0.3137],
          [0.2941, 0.2941, 0.2941,  ..., 0.2941, 0.2941, 0.2941],
          [0.1569, 0.1529, 0.1529,  ..., 0.1608, 0.1569, 0.1569]],

         [[0.3451, 0.3451, 0.3490,  ..., 0.3490, 0.3490, 0.3490],
          [0.3490, 0.3529, 0.3529,  ..., 0.3529, 0.3529, 0.3529],
          [0.3529, 0.3529, 0.3529,  ..., 0.3529, 0.3490, 0.3529],
          ...,
          [0.1804, 0.1804, 0.1804,  ..., 0.1804, 0.1765, 0.1804],
          [0.1647, 0.1647, 0.1647,  ..., 0.1686, 0.1608, 0.1647],
          [0.0706, 0.0667, 0.0667,  ..., 0.0745, 0.0745, 0.0706]]]]), tensor([[[[0.5137, 0.5098, 0.5137,  ..., 0.5137, 0.5137, 0.5137],
          [0.5098, 0.5137, 0.5137,  ..., 0.5098, 0.5137, 0.5098],
          [0.5098, 0.5098, 0.5137,  ..., 0.5098, 0.5098, 0.5098],
          ...,
          [0.3529, 0.3529, 0.3490,  ..., 0.3569, 0.3569, 0.3569],
          [0.3529, 0.3529, 0.3490,  ..., 0.3569, 0.3529, 0.3529],
          [0.3333, 0.3333, 0.3333,  ..., 0.3294, 0.3294, 0.3333]],

         [[0.4314, 0.4275, 0.4314,  ..., 0.4314, 0.4314, 0.4314],
          [0.4275, 0.4314, 0.4314,  ..., 0.4275, 0.4314, 0.4275],
          [0.4275, 0.4275, 0.4314,  ..., 0.4275, 0.4275, 0.4275],
          ...,
          [0.1490, 0.1490, 0.1451,  ..., 0.1490, 0.1490, 0.1490],
          [0.1529, 0.1529, 0.1529,  ..., 0.1569, 0.1529, 0.1529],
          [0.1451, 0.1451, 0.1451,  ..., 0.1490, 0.1451, 0.1490]],

         [[0.3647, 0.3608, 0.3647,  ..., 0.3647, 0.3647, 0.3647],
          [0.3608, 0.3647, 0.3647,  ..., 0.3608, 0.3647, 0.3608],
          [0.3608, 0.3608, 0.3647,  ..., 0.3608, 0.3608, 0.3608],
          ...,
          [0.0941, 0.0941, 0.0902,  ..., 0.0980, 0.0980, 0.0980],
          [0.1020, 0.0980, 0.0980,  ..., 0.1059, 0.1020, 0.1020],
          [0.0980, 0.1020, 0.1020,  ..., 0.1020, 0.0980, 0.1020]]]]), tensor([[[[0.6627, 0.6627, 0.6627,  ..., 0.6627, 0.6627, 0.6627],
          [0.6471, 0.6471, 0.6471,  ..., 0.6510, 0.6510, 0.6510],
          [0.6353, 0.6314, 0.6275,  ..., 0.6275, 0.6314, 0.6314],
          ...,
          [0.3294, 0.3294, 0.3216,  ..., 0.3294, 0.3294, 0.3333],
          [0.3373, 0.3373, 0.3333,  ..., 0.3294, 0.3333, 0.3373],
          [0.1647, 0.1686, 0.1647,  ..., 0.1647, 0.1686, 0.1686]],

         [[0.5529, 0.5529, 0.5529,  ..., 0.5529, 0.5529, 0.5529],
          [0.5412, 0.5412, 0.5451,  ..., 0.5490, 0.5451, 0.5451],
          [0.5373, 0.5333, 0.5333,  ..., 0.5373, 0.5373, 0.5373],
          ...,
          [0.1647, 0.1608, 0.1608,  ..., 0.1647, 0.1608, 0.1608],
          [0.1725, 0.1725, 0.1686,  ..., 0.1686, 0.1686, 0.1686],
          [0.0745, 0.0745, 0.0745,  ..., 0.0745, 0.0745, 0.0706]],

         [[0.4667, 0.4667, 0.4667,  ..., 0.4667, 0.4667, 0.4667],
          [0.4588, 0.4588, 0.4588,  ..., 0.4627, 0.4588, 0.4627],
          [0.4549, 0.4510, 0.4471,  ..., 0.4549, 0.4549, 0.4510],
          ...,
          [0.1294, 0.1255, 0.1255,  ..., 0.1373, 0.1333, 0.1333],
          [0.1255, 0.1255, 0.1255,  ..., 0.1255, 0.1255, 0.1294],
          [0.0471, 0.0471, 0.0431,  ..., 0.0510, 0.0510, 0.0510]]]]), tensor([[[[0.6706, 0.6706, 0.6706,  ..., 0.6706, 0.6706, 0.6706],
          [0.6510, 0.6510, 0.6549,  ..., 0.6510, 0.6510, 0.6549],
          [0.6275, 0.6275, 0.6275,  ..., 0.6314, 0.6275, 0.6275],
          ...,
          [0.3529, 0.3569, 0.3608,  ..., 0.3451, 0.3490, 0.3529],
          [0.3373, 0.3412, 0.3451,  ..., 0.3294, 0.3333, 0.3333],
          [0.2588, 0.2627, 0.2627,  ..., 0.2627, 0.2627, 0.2627]],

         [[0.5569, 0.5569, 0.5569,  ..., 0.5569, 0.5569, 0.5569],
          [0.5412, 0.5412, 0.5412,  ..., 0.5373, 0.5373, 0.5412],
          [0.5216, 0.5216, 0.5216,  ..., 0.5216, 0.5216, 0.5216],
          ...,
          [0.1765, 0.1725, 0.1804,  ..., 0.1686, 0.1686, 0.1686],
          [0.1569, 0.1608, 0.1647,  ..., 0.1529, 0.1529, 0.1529],
          [0.1373, 0.1373, 0.1373,  ..., 0.1412, 0.1412, 0.1373]],

         [[0.3922, 0.3922, 0.3922,  ..., 0.3922, 0.3922, 0.3922],
          [0.3804, 0.3804, 0.3804,  ..., 0.3804, 0.3804, 0.3843],
          [0.3647, 0.3647, 0.3647,  ..., 0.3686, 0.3686, 0.3686],
          ...,
          [0.0941, 0.0941, 0.0941,  ..., 0.0863, 0.0863, 0.0902],
          [0.0902, 0.0863, 0.0902,  ..., 0.0824, 0.0863, 0.0824],
          [0.0902, 0.0902, 0.0902,  ..., 0.0980, 0.0980, 0.0980]]]]), tensor([[[[0.6941, 0.6941, 0.6902,  ..., 0.6980, 0.6941, 0.6941],
          [0.6745, 0.6745, 0.6745,  ..., 0.6784, 0.6745, 0.6745],
          [0.6471, 0.6510, 0.6510,  ..., 0.6549, 0.6549, 0.6510],
          ...,
          [0.2941, 0.2980, 0.3020,  ..., 0.2902, 0.2863, 0.2941],
          [0.2706, 0.2706, 0.2706,  ..., 0.2667, 0.2627, 0.2667],
          [0.3020, 0.3020, 0.3059,  ..., 0.3020, 0.3059, 0.3059]],

         [[0.5569, 0.5569, 0.5529,  ..., 0.5569, 0.5569, 0.5569],
          [0.5490, 0.5490, 0.5490,  ..., 0.5451, 0.5451, 0.5451],
          [0.5373, 0.5412, 0.5412,  ..., 0.5412, 0.5412, 0.5412],
          ...,
          [0.1490, 0.1529, 0.1569,  ..., 0.1451, 0.1451, 0.1490],
          [0.1333, 0.1333, 0.1294,  ..., 0.1333, 0.1333, 0.1333],
          [0.1608, 0.1608, 0.1569,  ..., 0.1608, 0.1569, 0.1608]],

         [[0.4706, 0.4706, 0.4706,  ..., 0.4745, 0.4745, 0.4745],
          [0.4745, 0.4745, 0.4745,  ..., 0.4706, 0.4706, 0.4706],
          [0.4706, 0.4706, 0.4745,  ..., 0.4706, 0.4706, 0.4706],
          ...,
          [0.1294, 0.1294, 0.1294,  ..., 0.1216, 0.1216, 0.1294],
          [0.1373, 0.1373, 0.1373,  ..., 0.1373, 0.1333, 0.1333],
          [0.1451, 0.1451, 0.1451,  ..., 0.1490, 0.1451, 0.1451]]]]), tensor([[[[0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],
          [0.4353, 0.4353, 0.4353,  ..., 0.4392, 0.4392, 0.4392],
          [0.4353, 0.4353, 0.4314,  ..., 0.4314, 0.4314, 0.4353],
          ...,
          [0.5059, 0.5059, 0.5059,  ..., 0.5098, 0.5098, 0.5059],
          [0.5216, 0.5176, 0.5176,  ..., 0.5255, 0.5255, 0.5255],
          [0.4275, 0.4235, 0.4235,  ..., 0.4235, 0.4275, 0.4275]],

         [[0.3608, 0.3647, 0.3608,  ..., 0.3608, 0.3647, 0.3647],
          [0.3608, 0.3608, 0.3608,  ..., 0.3647, 0.3647, 0.3647],
          [0.3608, 0.3608, 0.3569,  ..., 0.3569, 0.3569, 0.3608],
          ...,
          [0.2510, 0.2510, 0.2549,  ..., 0.2549, 0.2510, 0.2510],
          [0.2588, 0.2588, 0.2588,  ..., 0.2588, 0.2627, 0.2588],
          [0.2196, 0.2157, 0.2157,  ..., 0.2196, 0.2157, 0.2157]],

         [[0.3059, 0.3059, 0.3059,  ..., 0.3059, 0.3059, 0.3059],
          [0.3020, 0.3020, 0.3020,  ..., 0.3059, 0.3059, 0.3059],
          [0.3020, 0.3020, 0.2980,  ..., 0.2980, 0.2980, 0.3020],
          ...,
          [0.1412, 0.1412, 0.1451,  ..., 0.1412, 0.1412, 0.1412],
          [0.1294, 0.1294, 0.1294,  ..., 0.1373, 0.1333, 0.1333],
          [0.1176, 0.1176, 0.1176,  ..., 0.1176, 0.1137, 0.1176]]]]), tensor([[[[0.5216, 0.5216, 0.5216,  ..., 0.5216, 0.5216, 0.5216],
          [0.5216, 0.5216, 0.5216,  ..., 0.5176, 0.5216, 0.5216],
          [0.5176, 0.5176, 0.5176,  ..., 0.5176, 0.5176, 0.5176],
          ...,
          [0.1608, 0.1647, 0.1647,  ..., 0.1608, 0.1608, 0.1647],
          [0.1961, 0.1961, 0.1922,  ..., 0.2039, 0.2000, 0.2000],
          [0.2078, 0.2078, 0.2078,  ..., 0.2078, 0.2078, 0.2118]],

         [[0.4745, 0.4745, 0.4745,  ..., 0.4745, 0.4745, 0.4745],
          [0.4745, 0.4745, 0.4745,  ..., 0.4706, 0.4745, 0.4745],
          [0.4706, 0.4706, 0.4706,  ..., 0.4706, 0.4706, 0.4706],
          ...,
          [0.0863, 0.0824, 0.0824,  ..., 0.0863, 0.0863, 0.0863],
          [0.0941, 0.0902, 0.0941,  ..., 0.0941, 0.0941, 0.0980],
          [0.1098, 0.1059, 0.1098,  ..., 0.1059, 0.1059, 0.1098]],

         [[0.4275, 0.4275, 0.4275,  ..., 0.4275, 0.4275, 0.4275],
          [0.4275, 0.4275, 0.4275,  ..., 0.4235, 0.4235, 0.4275],
          [0.4196, 0.4235, 0.4235,  ..., 0.4235, 0.4196, 0.4157],
          ...,
          [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588],
          [0.0706, 0.0667, 0.0706,  ..., 0.0706, 0.0706, 0.0745],
          [0.0863, 0.0863, 0.0863,  ..., 0.0863, 0.0863, 0.0863]]]]), tensor([[[[0.5686, 0.5686, 0.5686,  ..., 0.5725, 0.5686, 0.5686],
          [0.5647, 0.5647, 0.5686,  ..., 0.5647, 0.5647, 0.5686],
          [0.5647, 0.5647, 0.5647,  ..., 0.5647, 0.5647, 0.5686],
          ...,
          [0.2235, 0.2235, 0.2235,  ..., 0.2275, 0.2275, 0.2235],
          [0.2392, 0.2392, 0.2392,  ..., 0.2392, 0.2392, 0.2392],
          [0.1725, 0.1725, 0.1725,  ..., 0.1765, 0.1725, 0.1725]],

         [[0.5608, 0.5608, 0.5608,  ..., 0.5608, 0.5608, 0.5608],
          [0.5569, 0.5569, 0.5569,  ..., 0.5608, 0.5569, 0.5608],
          [0.5569, 0.5569, 0.5529,  ..., 0.5569, 0.5569, 0.5569],
          ...,
          [0.0941, 0.0941, 0.0941,  ..., 0.0941, 0.0941, 0.0941],
          [0.1098, 0.1098, 0.1098,  ..., 0.1137, 0.1137, 0.1137],
          [0.0902, 0.0902, 0.0902,  ..., 0.0941, 0.0902, 0.0902]],

         [[0.5725, 0.5725, 0.5725,  ..., 0.5725, 0.5725, 0.5725],
          [0.5686, 0.5686, 0.5725,  ..., 0.5686, 0.5686, 0.5725],
          [0.5686, 0.5686, 0.5686,  ..., 0.5686, 0.5686, 0.5686],
          ...,
          [0.0627, 0.0627, 0.0627,  ..., 0.0706, 0.0667, 0.0667],
          [0.0784, 0.0784, 0.0824,  ..., 0.0824, 0.0784, 0.0824],
          [0.0627, 0.0627, 0.0627,  ..., 0.0667, 0.0627, 0.0588]]]]), tensor([[[[0.5961, 0.5961, 0.5961,  ..., 0.5922, 0.5961, 0.5961],
          [0.5882, 0.5843, 0.5843,  ..., 0.5843, 0.5843, 0.5843],
          [0.5765, 0.5765, 0.5804,  ..., 0.5765, 0.5765, 0.5765],
          ...,
          [0.3804, 0.3804, 0.3843,  ..., 0.3804, 0.3804, 0.3804],
          [0.3647, 0.3647, 0.3647,  ..., 0.3686, 0.3686, 0.3686],
          [0.2549, 0.2588, 0.2549,  ..., 0.2588, 0.2588, 0.2549]],

         [[0.5333, 0.5333, 0.5333,  ..., 0.5333, 0.5333, 0.5333],
          [0.5333, 0.5333, 0.5294,  ..., 0.5333, 0.5333, 0.5333],
          [0.5255, 0.5294, 0.5294,  ..., 0.5255, 0.5255, 0.5255],
          ...,
          [0.1882, 0.1922, 0.1961,  ..., 0.1922, 0.1922, 0.1882],
          [0.1765, 0.1765, 0.1765,  ..., 0.1804, 0.1804, 0.1804],
          [0.1490, 0.1490, 0.1490,  ..., 0.1451, 0.1490, 0.1451]],

         [[0.4745, 0.4706, 0.4706,  ..., 0.4706, 0.4706, 0.4745],
          [0.4706, 0.4706, 0.4667,  ..., 0.4706, 0.4706, 0.4706],
          [0.4627, 0.4667, 0.4667,  ..., 0.4627, 0.4627, 0.4627],
          ...,
          [0.1294, 0.1333, 0.1373,  ..., 0.1333, 0.1333, 0.1294],
          [0.1333, 0.1333, 0.1333,  ..., 0.1294, 0.1333, 0.1333],
          [0.1137, 0.1176, 0.1137,  ..., 0.1176, 0.1137, 0.1098]]]]), tensor([[[[0.5216, 0.5216, 0.5216,  ..., 0.5216, 0.5216, 0.5216],
          [0.5216, 0.5216, 0.5216,  ..., 0.5255, 0.5216, 0.5255],
          [0.5176, 0.5216, 0.5216,  ..., 0.5216, 0.5176, 0.5176],
          ...,
          [0.2510, 0.2510, 0.2588,  ..., 0.2549, 0.2549, 0.2549],
          [0.3451, 0.3451, 0.3451,  ..., 0.3451, 0.3490, 0.3451],
          [0.2824, 0.2824, 0.2824,  ..., 0.2784, 0.2824, 0.2824]],

         [[0.5059, 0.5059, 0.5059,  ..., 0.5059, 0.5059, 0.5059],
          [0.5059, 0.5059, 0.5059,  ..., 0.5098, 0.5059, 0.5098],
          [0.5020, 0.5059, 0.5059,  ..., 0.5059, 0.5020, 0.5020],
          ...,
          [0.1608, 0.1608, 0.1686,  ..., 0.1725, 0.1686, 0.1647],
          [0.2353, 0.2314, 0.2353,  ..., 0.2392, 0.2392, 0.2353],
          [0.2196, 0.2196, 0.2196,  ..., 0.2196, 0.2196, 0.2157]],

         [[0.4627, 0.4627, 0.4627,  ..., 0.4627, 0.4667, 0.4667],
          [0.4627, 0.4627, 0.4627,  ..., 0.4667, 0.4667, 0.4667],
          [0.4588, 0.4627, 0.4627,  ..., 0.4627, 0.4588, 0.4588],
          ...,
          [0.2510, 0.2471, 0.2510,  ..., 0.2549, 0.2588, 0.2549],
          [0.2863, 0.2824, 0.2824,  ..., 0.2863, 0.2902, 0.2863],
          [0.2980, 0.3020, 0.3020,  ..., 0.2980, 0.2980, 0.2980]]]]), tensor([[[[0.5529, 0.5529, 0.5490,  ..., 0.5529, 0.5529, 0.5529],
          [0.5451, 0.5451, 0.5490,  ..., 0.5490, 0.5490, 0.5451],
          [0.5451, 0.5412, 0.5412,  ..., 0.5412, 0.5373, 0.5412],
          ...,
          [0.4706, 0.4706, 0.4706,  ..., 0.4824, 0.4784, 0.4706],
          [0.4745, 0.4745, 0.4784,  ..., 0.4980, 0.4902, 0.4824],
          [0.4000, 0.3961, 0.3961,  ..., 0.4078, 0.4039, 0.4039]],

         [[0.5059, 0.5059, 0.5059,  ..., 0.5059, 0.5059, 0.5059],
          [0.5020, 0.5059, 0.5059,  ..., 0.5020, 0.5020, 0.5020],
          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],
          ...,
          [0.2588, 0.2588, 0.2549,  ..., 0.2667, 0.2667, 0.2588],
          [0.2627, 0.2667, 0.2667,  ..., 0.2863, 0.2784, 0.2706],
          [0.2471, 0.2431, 0.2431,  ..., 0.2510, 0.2471, 0.2471]],

         [[0.4745, 0.4745, 0.4706,  ..., 0.4706, 0.4745, 0.4745],
          [0.4706, 0.4706, 0.4745,  ..., 0.4706, 0.4706, 0.4667],
          [0.4667, 0.4667, 0.4667,  ..., 0.4667, 0.4627, 0.4667],
          ...,
          [0.1529, 0.1490, 0.1490,  ..., 0.1608, 0.1608, 0.1529],
          [0.1451, 0.1451, 0.1490,  ..., 0.1686, 0.1608, 0.1529],
          [0.1608, 0.1608, 0.1608,  ..., 0.1647, 0.1647, 0.1608]]]]), tensor([[[[0.6039, 0.6039, 0.6039,  ..., 0.6039, 0.6039, 0.6039],
          [0.6078, 0.6078, 0.6078,  ..., 0.6157, 0.6157, 0.6078],
          [0.6196, 0.6196, 0.6157,  ..., 0.6235, 0.6235, 0.6196],
          ...,
          [0.5882, 0.5882, 0.5804,  ..., 0.5843, 0.5882, 0.5882],
          [0.5882, 0.5843, 0.5765,  ..., 0.5843, 0.5882, 0.5843],
          [0.4588, 0.4588, 0.4549,  ..., 0.4667, 0.4627, 0.4627]],

         [[0.5490, 0.5490, 0.5490,  ..., 0.5490, 0.5490, 0.5490],
          [0.5490, 0.5529, 0.5490,  ..., 0.5529, 0.5529, 0.5529],
          [0.5569, 0.5569, 0.5529,  ..., 0.5569, 0.5529, 0.5529],
          ...,
          [0.3686, 0.3686, 0.3608,  ..., 0.3608, 0.3647, 0.3686],
          [0.3569, 0.3529, 0.3490,  ..., 0.3569, 0.3647, 0.3608],
          [0.2510, 0.2510, 0.2510,  ..., 0.2588, 0.2588, 0.2549]],

         [[0.5059, 0.5059, 0.5059,  ..., 0.5059, 0.5059, 0.5059],
          [0.5059, 0.5059, 0.5059,  ..., 0.5059, 0.5020, 0.5059],
          [0.5020, 0.5020, 0.5020,  ..., 0.4980, 0.4980, 0.4980],
          ...,
          [0.2314, 0.2275, 0.2235,  ..., 0.2235, 0.2275, 0.2314],
          [0.2235, 0.2196, 0.2118,  ..., 0.2196, 0.2275, 0.2235],
          [0.1412, 0.1412, 0.1373,  ..., 0.1451, 0.1451, 0.1412]]]]), tensor([[[[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],
          [0.5020, 0.4980, 0.4980,  ..., 0.4980, 0.5020, 0.4980],
          [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4941, 0.4980],
          ...,
          [0.4039, 0.4039, 0.4039,  ..., 0.4118, 0.4118, 0.4118],
          [0.4078, 0.4078, 0.4039,  ..., 0.4157, 0.4118, 0.4078],
          [0.3882, 0.3882, 0.3882,  ..., 0.3843, 0.3882, 0.3882]],

         [[0.4706, 0.4706, 0.4706,  ..., 0.4706, 0.4706, 0.4706],
          [0.4745, 0.4706, 0.4745,  ..., 0.4706, 0.4745, 0.4745],
          [0.4706, 0.4706, 0.4706,  ..., 0.4745, 0.4745, 0.4706],
          ...,
          [0.2824, 0.2784, 0.2745,  ..., 0.2863, 0.2863, 0.2863],
          [0.2824, 0.2824, 0.2745,  ..., 0.2824, 0.2824, 0.2784],
          [0.2824, 0.2824, 0.2824,  ..., 0.2745, 0.2745, 0.2784]],

         [[0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],
          [0.4510, 0.4471, 0.4510,  ..., 0.4510, 0.4510, 0.4510],
          [0.4471, 0.4471, 0.4471,  ..., 0.4510, 0.4471, 0.4471],
          ...,
          [0.2980, 0.2941, 0.2902,  ..., 0.3020, 0.3059, 0.3059],
          [0.3059, 0.3059, 0.2980,  ..., 0.3098, 0.3059, 0.3020],
          [0.3373, 0.3373, 0.3373,  ..., 0.3294, 0.3333, 0.3333]]]]), tensor([[[[0.5098, 0.5098, 0.5098,  ..., 0.5098, 0.5098, 0.5098],
          [0.5098, 0.5098, 0.5098,  ..., 0.5059, 0.5098, 0.5098],
          [0.5059, 0.5059, 0.5059,  ..., 0.5059, 0.5059, 0.5059],
          ...,
          [0.3686, 0.4000, 0.4078,  ..., 0.3725, 0.3647, 0.3529],
          [0.3647, 0.3765, 0.3765,  ..., 0.3529, 0.3490, 0.3490],
          [0.2745, 0.2706, 0.2667,  ..., 0.2745, 0.2745, 0.2745]],

         [[0.4824, 0.4824, 0.4824,  ..., 0.4824, 0.4824, 0.4824],
          [0.4824, 0.4824, 0.4824,  ..., 0.4784, 0.4824, 0.4824],
          [0.4784, 0.4784, 0.4784,  ..., 0.4784, 0.4784, 0.4784],
          ...,
          [0.2902, 0.3216, 0.3294,  ..., 0.2824, 0.2784, 0.2745],
          [0.2863, 0.2980, 0.3020,  ..., 0.2745, 0.2706, 0.2706],
          [0.1922, 0.1882, 0.1882,  ..., 0.1922, 0.1922, 0.1922]],

         [[0.4431, 0.4431, 0.4431,  ..., 0.4431, 0.4431, 0.4431],
          [0.4431, 0.4431, 0.4431,  ..., 0.4392, 0.4431, 0.4431],
          [0.4392, 0.4392, 0.4392,  ..., 0.4392, 0.4392, 0.4392],
          ...,
          [0.2588, 0.2902, 0.2941,  ..., 0.2549, 0.2392, 0.2314],
          [0.2431, 0.2549, 0.2510,  ..., 0.2314, 0.2275, 0.2275],
          [0.1529, 0.1529, 0.1490,  ..., 0.1569, 0.1529, 0.1529]]]]), tensor([[[[0.5176, 0.5176, 0.5176,  ..., 0.5098, 0.5176, 0.5176],
          [0.5216, 0.5216, 0.5216,  ..., 0.5176, 0.5216, 0.5216],
          [0.5216, 0.5176, 0.5176,  ..., 0.5176, 0.5176, 0.5176],
          ...,
          [0.4353, 0.4510, 0.4510,  ..., 0.4314, 0.4431, 0.4392],
          [0.4275, 0.4314, 0.4392,  ..., 0.4314, 0.4275, 0.4275],
          [0.4196, 0.4196, 0.4235,  ..., 0.4196, 0.4196, 0.4196]],

         [[0.4941, 0.4941, 0.4941,  ..., 0.4941, 0.4941, 0.4941],
          [0.4941, 0.4941, 0.4941,  ..., 0.4941, 0.4941, 0.4902],
          [0.4941, 0.4941, 0.4902,  ..., 0.4902, 0.4941, 0.4902],
          ...,
          [0.3216, 0.3333, 0.3373,  ..., 0.3176, 0.3294, 0.3255],
          [0.3098, 0.3137, 0.3176,  ..., 0.3098, 0.3059, 0.3059],
          [0.2902, 0.2902, 0.2902,  ..., 0.2863, 0.2863, 0.2863]],

         [[0.4549, 0.4549, 0.4510,  ..., 0.4510, 0.4510, 0.4549],
          [0.4549, 0.4549, 0.4549,  ..., 0.4549, 0.4549, 0.4549],
          [0.4510, 0.4510, 0.4471,  ..., 0.4510, 0.4510, 0.4471],
          ...,
          [0.2824, 0.2941, 0.2941,  ..., 0.2784, 0.2902, 0.2902],
          [0.2627, 0.2667, 0.2745,  ..., 0.2706, 0.2627, 0.2627],
          [0.2314, 0.2314, 0.2353,  ..., 0.2392, 0.2392, 0.2392]]]]), tensor([[[[0.4706, 0.4706, 0.4745,  ..., 0.4667, 0.4706, 0.4706],
          [0.4706, 0.4706, 0.4706,  ..., 0.4745, 0.4706, 0.4706],
          [0.4706, 0.4706, 0.4706,  ..., 0.4745, 0.4706, 0.4745],
          ...,
          [0.4078, 0.4157, 0.4235,  ..., 0.4039, 0.4118, 0.4118],
          [0.3922, 0.3961, 0.4000,  ..., 0.4039, 0.4000, 0.3961],
          [0.3176, 0.3137, 0.3137,  ..., 0.3216, 0.3216, 0.3176]],

         [[0.4039, 0.4039, 0.4078,  ..., 0.4039, 0.4039, 0.4039],
          [0.4078, 0.4078, 0.4118,  ..., 0.4118, 0.4078, 0.4078],
          [0.4078, 0.4078, 0.4078,  ..., 0.4118, 0.4078, 0.4118],
          ...,
          [0.2980, 0.3098, 0.3176,  ..., 0.2980, 0.3059, 0.3059],
          [0.2941, 0.2980, 0.3059,  ..., 0.2980, 0.2941, 0.2902],
          [0.2314, 0.2275, 0.2275,  ..., 0.2353, 0.2314, 0.2314]],

         [[0.3490, 0.3490, 0.3490,  ..., 0.3451, 0.3451, 0.3490],
          [0.3490, 0.3490, 0.3529,  ..., 0.3529, 0.3490, 0.3490],
          [0.3490, 0.3490, 0.3490,  ..., 0.3529, 0.3490, 0.3529],
          ...,
          [0.2353, 0.2471, 0.2588,  ..., 0.2314, 0.2353, 0.2392],
          [0.2275, 0.2353, 0.2392,  ..., 0.2353, 0.2275, 0.2235],
          [0.1922, 0.1882, 0.1922,  ..., 0.1961, 0.1961, 0.1961]]]]), tensor([[[[0.5412, 0.5412, 0.5373,  ..., 0.5373, 0.5373, 0.5373],
          [0.5373, 0.5373, 0.5373,  ..., 0.5373, 0.5373, 0.5373],
          [0.5333, 0.5373, 0.5333,  ..., 0.5333, 0.5333, 0.5333],
          ...,
          [0.4157, 0.4275, 0.4353,  ..., 0.4235, 0.4078, 0.4118],
          [0.4078, 0.4118, 0.4118,  ..., 0.3961, 0.4000, 0.4039],
          [0.3843, 0.3843, 0.3804,  ..., 0.3961, 0.3882, 0.3882]],

         [[0.5137, 0.5137, 0.5098,  ..., 0.5098, 0.5098, 0.5098],
          [0.5098, 0.5098, 0.5098,  ..., 0.5098, 0.5098, 0.5098],
          [0.5059, 0.5098, 0.5059,  ..., 0.5059, 0.5059, 0.5059],
          ...,
          [0.3098, 0.3176, 0.3294,  ..., 0.3137, 0.3020, 0.3020],
          [0.3020, 0.3020, 0.3059,  ..., 0.2824, 0.2902, 0.2980],
          [0.2824, 0.2824, 0.2784,  ..., 0.2902, 0.2863, 0.2863]],

         [[0.4902, 0.4902, 0.4863,  ..., 0.4863, 0.4863, 0.4863],
          [0.4863, 0.4863, 0.4863,  ..., 0.4863, 0.4863, 0.4863],
          [0.4824, 0.4824, 0.4824,  ..., 0.4784, 0.4784, 0.4784],
          ...,
          [0.2667, 0.2745, 0.2863,  ..., 0.2706, 0.2588, 0.2588],
          [0.2510, 0.2510, 0.2549,  ..., 0.2392, 0.2471, 0.2471],
          [0.2392, 0.2353, 0.2314,  ..., 0.2471, 0.2431, 0.2353]]]]), tensor([[[[0.5137, 0.5137, 0.5137,  ..., 0.5137, 0.5137, 0.5137],
          [0.5176, 0.5176, 0.5176,  ..., 0.5176, 0.5176, 0.5176],
          [0.5255, 0.5216, 0.5216,  ..., 0.5216, 0.5255, 0.5216],
          ...,
          [0.4235, 0.4196, 0.4157,  ..., 0.4078, 0.4118, 0.4157],
          [0.4118, 0.4118, 0.4078,  ..., 0.4039, 0.4078, 0.4078],
          [0.3098, 0.3098, 0.3059,  ..., 0.3176, 0.3137, 0.3137]],

         [[0.4627, 0.4627, 0.4627,  ..., 0.4627, 0.4627, 0.4627],
          [0.4784, 0.4784, 0.4784,  ..., 0.4745, 0.4784, 0.4784],
          [0.4941, 0.4941, 0.4980,  ..., 0.4902, 0.4941, 0.4941],
          ...,
          [0.2980, 0.2941, 0.2902,  ..., 0.2824, 0.2863, 0.2941],
          [0.2941, 0.2902, 0.2863,  ..., 0.2824, 0.2863, 0.2902],
          [0.2000, 0.2000, 0.1961,  ..., 0.2078, 0.2039, 0.2039]],

         [[0.4157, 0.4118, 0.4118,  ..., 0.4157, 0.4118, 0.4118],
          [0.4353, 0.4353, 0.4353,  ..., 0.4275, 0.4353, 0.4353],
          [0.4510, 0.4510, 0.4510,  ..., 0.4471, 0.4510, 0.4510],
          ...,
          [0.2314, 0.2353, 0.2314,  ..., 0.2235, 0.2235, 0.2275],
          [0.2314, 0.2353, 0.2314,  ..., 0.2235, 0.2235, 0.2275],
          [0.1686, 0.1686, 0.1647,  ..., 0.1804, 0.1765, 0.1765]]]]), tensor([[[[0.4353, 0.4353, 0.4353,  ..., 0.4353, 0.4353, 0.4353],
          [0.4314, 0.4314, 0.4314,  ..., 0.4314, 0.4314, 0.4314],
          [0.4235, 0.4235, 0.4235,  ..., 0.4275, 0.4275, 0.4235],
          ...,
          [0.5020, 0.5020, 0.4980,  ..., 0.4980, 0.5020, 0.5020],
          [0.5059, 0.5020, 0.5020,  ..., 0.5059, 0.5059, 0.5059],
          [0.4627, 0.4627, 0.4627,  ..., 0.4588, 0.4588, 0.4588]],

         [[0.3373, 0.3373, 0.3373,  ..., 0.3373, 0.3373, 0.3373],
          [0.3333, 0.3333, 0.3333,  ..., 0.3333, 0.3333, 0.3333],
          [0.3255, 0.3255, 0.3255,  ..., 0.3294, 0.3294, 0.3255],
          ...,
          [0.3804, 0.3765, 0.3725,  ..., 0.3725, 0.3765, 0.3765],
          [0.3804, 0.3765, 0.3765,  ..., 0.3804, 0.3804, 0.3765],
          [0.3490, 0.3490, 0.3490,  ..., 0.3451, 0.3451, 0.3451]],

         [[0.2510, 0.2510, 0.2510,  ..., 0.2510, 0.2510, 0.2510],
          [0.2471, 0.2471, 0.2471,  ..., 0.2471, 0.2471, 0.2471],
          [0.2392, 0.2392, 0.2392,  ..., 0.2431, 0.2431, 0.2392],
          ...,
          [0.3176, 0.3176, 0.3137,  ..., 0.3137, 0.3176, 0.3176],
          [0.3176, 0.3137, 0.3137,  ..., 0.3176, 0.3216, 0.3176],
          [0.3137, 0.3137, 0.3137,  ..., 0.3137, 0.3137, 0.3137]]]]), tensor([[[[0.4902, 0.4941, 0.4902,  ..., 0.4941, 0.4941, 0.4941],
          [0.4902, 0.4902, 0.4902,  ..., 0.4902, 0.4902, 0.4902],
          [0.4902, 0.4902, 0.4941,  ..., 0.4863, 0.4863, 0.4902],
          ...,
          [0.4314, 0.4157, 0.4039,  ..., 0.4392, 0.4314, 0.4353],
          [0.4314, 0.4275, 0.4235,  ..., 0.4314, 0.4275, 0.4314],
          [0.3020, 0.3020, 0.3059,  ..., 0.2980, 0.3020, 0.3020]],

         [[0.4353, 0.4392, 0.4353,  ..., 0.4392, 0.4392, 0.4392],
          [0.4392, 0.4392, 0.4392,  ..., 0.4353, 0.4353, 0.4353],
          [0.4353, 0.4353, 0.4392,  ..., 0.4314, 0.4314, 0.4353],
          ...,
          [0.2902, 0.2745, 0.2627,  ..., 0.2980, 0.2941, 0.2941],
          [0.2941, 0.2941, 0.2863,  ..., 0.2941, 0.2941, 0.2941],
          [0.1882, 0.1882, 0.1882,  ..., 0.1843, 0.1843, 0.1882]],

         [[0.4000, 0.4039, 0.4000,  ..., 0.4039, 0.4039, 0.4039],
          [0.4000, 0.4039, 0.4000,  ..., 0.4000, 0.4000, 0.4000],
          [0.4000, 0.4000, 0.4039,  ..., 0.3961, 0.3961, 0.4000],
          ...,
          [0.2078, 0.1922, 0.1882,  ..., 0.2118, 0.2118, 0.2157],
          [0.2196, 0.2196, 0.2157,  ..., 0.2235, 0.2196, 0.2196],
          [0.1255, 0.1255, 0.1294,  ..., 0.1294, 0.1255, 0.1255]]]]), tensor([[[[0.5216, 0.5216, 0.5216,  ..., 0.5216, 0.5216, 0.5255],
          [0.5216, 0.5216, 0.5176,  ..., 0.5216, 0.5216, 0.5216],
          [0.5216, 0.5176, 0.5176,  ..., 0.5176, 0.5176, 0.5216],
          ...,
          [0.5098, 0.5216, 0.5294,  ..., 0.5333, 0.5255, 0.5137],
          [0.5294, 0.5216, 0.5098,  ..., 0.5098, 0.5216, 0.5333],
          [0.2902, 0.2863, 0.2824,  ..., 0.2902, 0.2902, 0.2902]],

         [[0.4706, 0.4706, 0.4706,  ..., 0.4706, 0.4745, 0.4745],
          [0.4706, 0.4706, 0.4667,  ..., 0.4706, 0.4706, 0.4706],
          [0.4706, 0.4667, 0.4667,  ..., 0.4667, 0.4667, 0.4706],
          ...,
          [0.3490, 0.3569, 0.3686,  ..., 0.3686, 0.3608, 0.3490],
          [0.3804, 0.3725, 0.3608,  ..., 0.3608, 0.3686, 0.3765],
          [0.1882, 0.1843, 0.1804,  ..., 0.1961, 0.1961, 0.1922]],

         [[0.4392, 0.4353, 0.4353,  ..., 0.4353, 0.4392, 0.4392],
          [0.4392, 0.4353, 0.4353,  ..., 0.4392, 0.4392, 0.4392],
          [0.4353, 0.4353, 0.4353,  ..., 0.4353, 0.4314, 0.4353],
          ...,
          [0.2392, 0.2510, 0.2549,  ..., 0.2510, 0.2431, 0.2353],
          [0.2745, 0.2667, 0.2588,  ..., 0.2471, 0.2588, 0.2745],
          [0.1529, 0.1490, 0.1451,  ..., 0.1569, 0.1569, 0.1529]]]]), tensor([[[[0.6314, 0.6275, 0.6275,  ..., 0.6275, 0.6314, 0.6314],
          [0.6275, 0.6275, 0.6275,  ..., 0.6235, 0.6275, 0.6275],
          [0.6196, 0.6235, 0.6235,  ..., 0.6235, 0.6235, 0.6235],
          ...,
          [0.4431, 0.4706, 0.4784,  ..., 0.4471, 0.4471, 0.4353],
          [0.4275, 0.4235, 0.4196,  ..., 0.4196, 0.4275, 0.4314],
          [0.2667, 0.2588, 0.2588,  ..., 0.2784, 0.2745, 0.2706]],

         [[0.5451, 0.5412, 0.5412,  ..., 0.5451, 0.5451, 0.5451],
          [0.5412, 0.5412, 0.5412,  ..., 0.5412, 0.5412, 0.5373],
          [0.5294, 0.5333, 0.5333,  ..., 0.5333, 0.5333, 0.5333],
          ...,
          [0.3255, 0.3451, 0.3529,  ..., 0.3294, 0.3255, 0.3137],
          [0.3255, 0.3255, 0.3216,  ..., 0.3176, 0.3255, 0.3294],
          [0.2000, 0.2000, 0.1961,  ..., 0.2078, 0.2039, 0.2000]],

         [[0.4627, 0.4588, 0.4588,  ..., 0.4627, 0.4588, 0.4627],
          [0.4588, 0.4588, 0.4588,  ..., 0.4588, 0.4627, 0.4627],
          [0.4588, 0.4588, 0.4627,  ..., 0.4627, 0.4627, 0.4627],
          ...,
          [0.2353, 0.2588, 0.2667,  ..., 0.2471, 0.2392, 0.2275],
          [0.2431, 0.2431, 0.2392,  ..., 0.2314, 0.2392, 0.2431],
          [0.1647, 0.1647, 0.1686,  ..., 0.1725, 0.1686, 0.1647]]]]), tensor([[[[0.5333, 0.5333, 0.5333,  ..., 0.5333, 0.5333, 0.5333],
          [0.5294, 0.5294, 0.5333,  ..., 0.5294, 0.5294, 0.5294],
          [0.5255, 0.5255, 0.5255,  ..., 0.5255, 0.5255, 0.5255],
          ...,
          [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4510, 0.4510],
          [0.4314, 0.4314, 0.4353,  ..., 0.4275, 0.4275, 0.4314],
          [0.2706, 0.2706, 0.2706,  ..., 0.2745, 0.2745, 0.2745]],

         [[0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],
          [0.4431, 0.4431, 0.4471,  ..., 0.4431, 0.4431, 0.4431],
          [0.4392, 0.4392, 0.4392,  ..., 0.4392, 0.4431, 0.4392],
          ...,
          [0.2941, 0.2902, 0.2902,  ..., 0.2902, 0.2941, 0.2941],
          [0.2824, 0.2824, 0.2863,  ..., 0.2784, 0.2784, 0.2824],
          [0.1490, 0.1490, 0.1490,  ..., 0.1529, 0.1529, 0.1529]],

         [[0.3647, 0.3647, 0.3647,  ..., 0.3647, 0.3647, 0.3647],
          [0.3608, 0.3608, 0.3647,  ..., 0.3608, 0.3608, 0.3608],
          [0.3569, 0.3569, 0.3569,  ..., 0.3569, 0.3608, 0.3569],
          ...,
          [0.1882, 0.1882, 0.1882,  ..., 0.1882, 0.1882, 0.1882],
          [0.1804, 0.1804, 0.1804,  ..., 0.1765, 0.1804, 0.1843],
          [0.0824, 0.0824, 0.0784,  ..., 0.0863, 0.0863, 0.0863]]]]), tensor([[[[0.4510, 0.4510, 0.4471,  ..., 0.4471, 0.4510, 0.4510],
          [0.4431, 0.4431, 0.4431,  ..., 0.4431, 0.4392, 0.4392],
          [0.4392, 0.4392, 0.4392,  ..., 0.4353, 0.4353, 0.4392],
          ...,
          [0.5176, 0.5216, 0.5255,  ..., 0.5020, 0.5059, 0.5098],
          [0.5098, 0.5137, 0.5137,  ..., 0.5098, 0.5059, 0.5059],
          [0.4392, 0.4392, 0.4353,  ..., 0.4471, 0.4471, 0.4431]],

         [[0.2627, 0.2627, 0.2588,  ..., 0.2588, 0.2627, 0.2627],
          [0.2549, 0.2549, 0.2549,  ..., 0.2549, 0.2510, 0.2510],
          [0.2510, 0.2510, 0.2471,  ..., 0.2471, 0.2471, 0.2510],
          ...,
          [0.4471, 0.4549, 0.4549,  ..., 0.4314, 0.4353, 0.4392],
          [0.4353, 0.4392, 0.4392,  ..., 0.4353, 0.4353, 0.4353],
          [0.3804, 0.3804, 0.3765,  ..., 0.3882, 0.3843, 0.3843]],

         [[0.1098, 0.1059, 0.1020,  ..., 0.1098, 0.1098, 0.1098],
          [0.0980, 0.0980, 0.0980,  ..., 0.1059, 0.0980, 0.0980],
          [0.0980, 0.0941, 0.0941,  ..., 0.0941, 0.0941, 0.0941],
          ...,
          [0.4039, 0.4078, 0.4078,  ..., 0.3843, 0.3843, 0.3922],
          [0.3961, 0.4000, 0.4000,  ..., 0.3922, 0.3922, 0.3922],
          [0.3490, 0.3451, 0.3451,  ..., 0.3569, 0.3490, 0.3451]]]]), tensor([[[[0.5569, 0.5569, 0.5569,  ..., 0.5569, 0.5569, 0.5569],
          [0.5529, 0.5529, 0.5529,  ..., 0.5490, 0.5490, 0.5490],
          [0.5490, 0.5490, 0.5490,  ..., 0.5412, 0.5412, 0.5451],
          ...,
          [0.4863, 0.4902, 0.4902,  ..., 0.4980, 0.4941, 0.4863],
          [0.4902, 0.4902, 0.4863,  ..., 0.4863, 0.4863, 0.4863],
          [0.2549, 0.2549, 0.2510,  ..., 0.2549, 0.2588, 0.2588]],

         [[0.4784, 0.4784, 0.4784,  ..., 0.4784, 0.4784, 0.4784],
          [0.4745, 0.4745, 0.4745,  ..., 0.4745, 0.4745, 0.4745],
          [0.4706, 0.4706, 0.4706,  ..., 0.4706, 0.4706, 0.4706],
          ...,
          [0.3451, 0.3451, 0.3490,  ..., 0.3529, 0.3490, 0.3451],
          [0.3529, 0.3490, 0.3451,  ..., 0.3490, 0.3490, 0.3529],
          [0.1451, 0.1412, 0.1373,  ..., 0.1451, 0.1451, 0.1451]],

         [[0.2824, 0.2824, 0.2824,  ..., 0.2824, 0.2824, 0.2824],
          [0.2784, 0.2784, 0.2784,  ..., 0.2784, 0.2784, 0.2784],
          [0.2745, 0.2745, 0.2745,  ..., 0.2745, 0.2745, 0.2745],
          ...,
          [0.1608, 0.1608, 0.1608,  ..., 0.1725, 0.1647, 0.1608],
          [0.1569, 0.1569, 0.1529,  ..., 0.1569, 0.1569, 0.1608],
          [0.0353, 0.0353, 0.0314,  ..., 0.0353, 0.0353, 0.0392]]]]), tensor([[[[0.5569, 0.5569, 0.5608,  ..., 0.5569, 0.5569, 0.5569],
          [0.5608, 0.5569, 0.5569,  ..., 0.5569, 0.5569, 0.5608],
          [0.5529, 0.5529, 0.5569,  ..., 0.5529, 0.5529, 0.5529],
          ...,
          [0.5255, 0.5294, 0.5294,  ..., 0.5098, 0.5137, 0.5216],
          [0.5294, 0.5294, 0.5294,  ..., 0.5216, 0.5216, 0.5255],
          [0.5137, 0.5137, 0.5137,  ..., 0.5255, 0.5176, 0.5176]],

         [[0.4588, 0.4588, 0.4588,  ..., 0.4588, 0.4588, 0.4588],
          [0.4627, 0.4588, 0.4588,  ..., 0.4588, 0.4588, 0.4627],
          [0.4549, 0.4549, 0.4588,  ..., 0.4549, 0.4549, 0.4549],
          ...,
          [0.4118, 0.4118, 0.4196,  ..., 0.3882, 0.4000, 0.4039],
          [0.4118, 0.4118, 0.4157,  ..., 0.4039, 0.4039, 0.4078],
          [0.4000, 0.4000, 0.3961,  ..., 0.4039, 0.4039, 0.4039]],

         [[0.2118, 0.2118, 0.2118,  ..., 0.2078, 0.2078, 0.2078],
          [0.2118, 0.2078, 0.2078,  ..., 0.2118, 0.2078, 0.2118],
          [0.2039, 0.2039, 0.2039,  ..., 0.2000, 0.2039, 0.2039],
          ...,
          [0.2667, 0.2667, 0.2706,  ..., 0.2471, 0.2549, 0.2627],
          [0.2627, 0.2627, 0.2667,  ..., 0.2588, 0.2549, 0.2588],
          [0.2471, 0.2471, 0.2431,  ..., 0.2549, 0.2510, 0.2510]]]]), tensor([[[[0.5020, 0.5020, 0.4980,  ..., 0.5020, 0.5020, 0.5020],
          [0.5020, 0.5020, 0.5020,  ..., 0.4980, 0.5020, 0.5020],
          [0.5020, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],
          ...,
          [0.4157, 0.4275, 0.4471,  ..., 0.4314, 0.4275, 0.4235],
          [0.4314, 0.4314, 0.4314,  ..., 0.4392, 0.4392, 0.4353],
          [0.4275, 0.4235, 0.4235,  ..., 0.4235, 0.4275, 0.4275]],

         [[0.3608, 0.3608, 0.3569,  ..., 0.3608, 0.3608, 0.3608],
          [0.3647, 0.3608, 0.3608,  ..., 0.3608, 0.3647, 0.3647],
          [0.3608, 0.3608, 0.3608,  ..., 0.3569, 0.3608, 0.3608],
          ...,
          [0.3412, 0.3529, 0.3647,  ..., 0.3529, 0.3529, 0.3451],
          [0.3490, 0.3490, 0.3529,  ..., 0.3608, 0.3608, 0.3569],
          [0.3569, 0.3529, 0.3529,  ..., 0.3490, 0.3529, 0.3529]],

         [[0.2667, 0.2627, 0.2627,  ..., 0.2667, 0.2667, 0.2667],
          [0.2588, 0.2549, 0.2588,  ..., 0.2549, 0.2549, 0.2549],
          [0.2549, 0.2510, 0.2510,  ..., 0.2510, 0.2510, 0.2549],
          ...,
          [0.2824, 0.2980, 0.3176,  ..., 0.2980, 0.2941, 0.2902],
          [0.3020, 0.3020, 0.3020,  ..., 0.3098, 0.3098, 0.3059],
          [0.3020, 0.2980, 0.2902,  ..., 0.3020, 0.2980, 0.3020]]]]), tensor([[[[0.5373, 0.5373, 0.5373,  ..., 0.5373, 0.5373, 0.5373],
          [0.5294, 0.5294, 0.5333,  ..., 0.5294, 0.5294, 0.5294],
          [0.5333, 0.5333, 0.5333,  ..., 0.5294, 0.5333, 0.5333],
          ...,
          [0.4078, 0.4078, 0.4078,  ..., 0.4078, 0.4039, 0.4078],
          [0.4196, 0.4196, 0.4235,  ..., 0.4235, 0.4275, 0.4235],
          [0.3451, 0.3451, 0.3412,  ..., 0.3490, 0.3490, 0.3451]],

         [[0.4667, 0.4667, 0.4667,  ..., 0.4667, 0.4667, 0.4667],
          [0.4667, 0.4667, 0.4627,  ..., 0.4667, 0.4667, 0.4667],
          [0.4627, 0.4627, 0.4588,  ..., 0.4588, 0.4588, 0.4588],
          ...,
          [0.2588, 0.2588, 0.2549,  ..., 0.2588, 0.2549, 0.2549],
          [0.2784, 0.2784, 0.2784,  ..., 0.2784, 0.2784, 0.2784],
          [0.2118, 0.2118, 0.2118,  ..., 0.2157, 0.2157, 0.2118]],

         [[0.3373, 0.3333, 0.3373,  ..., 0.3373, 0.3373, 0.3373],
          [0.3333, 0.3333, 0.3333,  ..., 0.3333, 0.3333, 0.3333],
          [0.3294, 0.3333, 0.3294,  ..., 0.3294, 0.3294, 0.3294],
          ...,
          [0.1098, 0.1098, 0.1059,  ..., 0.1098, 0.1059, 0.1059],
          [0.1255, 0.1255, 0.1255,  ..., 0.1294, 0.1255, 0.1255],
          [0.0863, 0.0863, 0.0824,  ..., 0.0902, 0.0902, 0.0863]]]]), tensor([[[[0.6353, 0.6314, 0.6353,  ..., 0.6314, 0.6314, 0.6314],
          [0.6235, 0.6235, 0.6275,  ..., 0.6275, 0.6275, 0.6235],
          [0.6235, 0.6196, 0.6196,  ..., 0.6196, 0.6196, 0.6196],
          ...,
          [0.4745, 0.4784, 0.4784,  ..., 0.4902, 0.4784, 0.4706],
          [0.4588, 0.4588, 0.4627,  ..., 0.4627, 0.4627, 0.4588],
          [0.4196, 0.4196, 0.4157,  ..., 0.4235, 0.4235, 0.4235]],

         [[0.5373, 0.5333, 0.5373,  ..., 0.5333, 0.5333, 0.5333],
          [0.5255, 0.5255, 0.5294,  ..., 0.5294, 0.5294, 0.5255],
          [0.5216, 0.5216, 0.5216,  ..., 0.5216, 0.5216, 0.5216],
          ...,
          [0.3255, 0.3294, 0.3294,  ..., 0.3451, 0.3294, 0.3255],
          [0.3098, 0.3098, 0.3137,  ..., 0.3137, 0.3137, 0.3098],
          [0.2784, 0.2745, 0.2745,  ..., 0.2824, 0.2784, 0.2784]],

         [[0.4157, 0.4157, 0.4196,  ..., 0.4157, 0.4157, 0.4157],
          [0.4039, 0.4039, 0.4078,  ..., 0.4078, 0.4078, 0.4039],
          [0.4039, 0.4039, 0.4000,  ..., 0.4000, 0.4000, 0.4000],
          ...,
          [0.1725, 0.1765, 0.1765,  ..., 0.1922, 0.1765, 0.1725],
          [0.1490, 0.1529, 0.1529,  ..., 0.1608, 0.1608, 0.1569],
          [0.1294, 0.1255, 0.1255,  ..., 0.1333, 0.1333, 0.1333]]]]), tensor([[[[0.4980, 0.4980, 0.4980,  ..., 0.4941, 0.4980, 0.4980],
          [0.4980, 0.4980, 0.4941,  ..., 0.4980, 0.4941, 0.4980],
          [0.4980, 0.4980, 0.4941,  ..., 0.4980, 0.4941, 0.4980],
          ...,
          [0.3608, 0.3608, 0.3608,  ..., 0.3569, 0.3569, 0.3608],
          [0.3647, 0.3686, 0.3647,  ..., 0.3529, 0.3529, 0.3608],
          [0.2196, 0.2196, 0.2157,  ..., 0.2275, 0.2235, 0.2235]],

         [[0.4980, 0.4980, 0.4980,  ..., 0.4941, 0.4980, 0.4980],
          [0.4980, 0.4980, 0.4941,  ..., 0.4980, 0.4941, 0.4980],
          [0.4980, 0.4980, 0.4941,  ..., 0.4980, 0.4941, 0.4980],
          ...,
          [0.2784, 0.2745, 0.2784,  ..., 0.2745, 0.2745, 0.2745],
          [0.2784, 0.2784, 0.2784,  ..., 0.2667, 0.2667, 0.2706],
          [0.1490, 0.1490, 0.1490,  ..., 0.1569, 0.1569, 0.1569]],

         [[0.4510, 0.4510, 0.4510,  ..., 0.4471, 0.4510, 0.4510],
          [0.4510, 0.4510, 0.4471,  ..., 0.4510, 0.4471, 0.4510],
          [0.4510, 0.4510, 0.4471,  ..., 0.4510, 0.4471, 0.4510],
          ...,
          [0.1686, 0.1647, 0.1647,  ..., 0.1686, 0.1686, 0.1725],
          [0.1725, 0.1725, 0.1686,  ..., 0.1529, 0.1569, 0.1686],
          [0.0863, 0.0863, 0.0824,  ..., 0.0902, 0.0863, 0.0902]]]]), tensor([[[[0.4941, 0.4941, 0.4941,  ..., 0.4941, 0.4902, 0.4902],
          [0.4941, 0.4941, 0.4941,  ..., 0.4863, 0.4902, 0.4941],
          [0.4863, 0.4863, 0.4863,  ..., 0.4863, 0.4902, 0.4863],
          ...,
          [0.3961, 0.3961, 0.3804,  ..., 0.3922, 0.3922, 0.3922],
          [0.3765, 0.3686, 0.3686,  ..., 0.3843, 0.3843, 0.3804],
          [0.4000, 0.4039, 0.4000,  ..., 0.4118, 0.4078, 0.4039]],

         [[0.4706, 0.4706, 0.4706,  ..., 0.4706, 0.4706, 0.4706],
          [0.4706, 0.4706, 0.4706,  ..., 0.4706, 0.4706, 0.4706],
          [0.4706, 0.4706, 0.4706,  ..., 0.4706, 0.4706, 0.4706],
          ...,
          [0.3176, 0.3137, 0.2980,  ..., 0.3059, 0.3059, 0.3098],
          [0.2941, 0.2863, 0.2863,  ..., 0.3020, 0.3020, 0.2980],
          [0.3490, 0.3490, 0.3529,  ..., 0.3529, 0.3569, 0.3529]],

         [[0.4353, 0.4353, 0.4353,  ..., 0.4353, 0.4353, 0.4353],
          [0.4392, 0.4392, 0.4392,  ..., 0.4353, 0.4353, 0.4392],
          [0.4353, 0.4353, 0.4353,  ..., 0.4353, 0.4353, 0.4353],
          ...,
          [0.2235, 0.2196, 0.2039,  ..., 0.2157, 0.2157, 0.2157],
          [0.2000, 0.1961, 0.1922,  ..., 0.2118, 0.2118, 0.2078],
          [0.3294, 0.3294, 0.3333,  ..., 0.3373, 0.3333, 0.3294]]]]), tensor([[[[0.5490, 0.5490, 0.5529,  ..., 0.5490, 0.5490, 0.5490],
          [0.5216, 0.5216, 0.5255,  ..., 0.5255, 0.5255, 0.5216],
          [0.5216, 0.5216, 0.5216,  ..., 0.5216, 0.5255, 0.5216],
          ...,
          [0.4510, 0.4431, 0.4392,  ..., 0.4431, 0.4431, 0.4510],
          [0.4235, 0.4196, 0.4157,  ..., 0.4275, 0.4275, 0.4196],
          [0.3804, 0.3804, 0.3804,  ..., 0.3882, 0.3882, 0.3843]],

         [[0.5216, 0.5255, 0.5255,  ..., 0.5255, 0.5216, 0.5216],
          [0.4941, 0.4941, 0.4980,  ..., 0.4980, 0.4980, 0.4941],
          [0.4941, 0.4941, 0.4941,  ..., 0.4980, 0.4980, 0.4941],
          ...,
          [0.3333, 0.3294, 0.3255,  ..., 0.3216, 0.3255, 0.3373],
          [0.3020, 0.3020, 0.3020,  ..., 0.3059, 0.3059, 0.3020],
          [0.2784, 0.2784, 0.2745,  ..., 0.2784, 0.2824, 0.2784]],

         [[0.4824, 0.4863, 0.4863,  ..., 0.4824, 0.4824, 0.4824],
          [0.4588, 0.4627, 0.4627,  ..., 0.4627, 0.4627, 0.4588],
          [0.4588, 0.4588, 0.4588,  ..., 0.4588, 0.4588, 0.4549],
          ...,
          [0.2863, 0.2784, 0.2745,  ..., 0.2706, 0.2706, 0.2824],
          [0.2588, 0.2588, 0.2549,  ..., 0.2588, 0.2627, 0.2588],
          [0.2314, 0.2275, 0.2275,  ..., 0.2353, 0.2353, 0.2314]]]])]
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 219, in <module>
    inputs, labels = data[0].cuda(), data[1].cuda()
AttributeError: 'list' object has no attribute 'cuda'
alpha set
parameters: 
batch_size = 64
shuffle_train = True
num_workers = 8
epoch = 50
augmentation = numpy.roll + colorJitter
Start training, 2023-07-06 04:48:20.331303
tensor([[[[0.5451, 0.5451, 0.5451,  ..., 0.5451, 0.5490, 0.5451],
          [0.5529, 0.5529, 0.5529,  ..., 0.5529, 0.5529, 0.5529],
          [0.5529, 0.5569, 0.5529,  ..., 0.5569, 0.5569, 0.5529],
          ...,
          [0.2824, 0.2941, 0.3020,  ..., 0.2824, 0.2941, 0.2902],
          [0.3216, 0.3020, 0.2824,  ..., 0.3098, 0.3176, 0.3216],
          [0.1647, 0.1725, 0.1765,  ..., 0.1647, 0.1647, 0.1647]],

         [[0.4471, 0.4471, 0.4471,  ..., 0.4510, 0.4510, 0.4510],
          [0.4627, 0.4627, 0.4627,  ..., 0.4627, 0.4588, 0.4627],
          [0.4667, 0.4706, 0.4667,  ..., 0.4667, 0.4667, 0.4667],
          ...,
          [0.2431, 0.2510, 0.2549,  ..., 0.2392, 0.2549, 0.2471],
          [0.2863, 0.2667, 0.2431,  ..., 0.2824, 0.2863, 0.2902],
          [0.1451, 0.1490, 0.1490,  ..., 0.1451, 0.1451, 0.1451]],

         [[0.3647, 0.3647, 0.3647,  ..., 0.3647, 0.3647, 0.3647],
          [0.3843, 0.3843, 0.3843,  ..., 0.3843, 0.3843, 0.3843],
          [0.3843, 0.3882, 0.3843,  ..., 0.3882, 0.3882, 0.3843],
          ...,
          [0.2353, 0.2471, 0.2549,  ..., 0.2353, 0.2510, 0.2431],
          [0.2824, 0.2667, 0.2431,  ..., 0.2745, 0.2824, 0.2863],
          [0.1686, 0.1686, 0.1686,  ..., 0.1686, 0.1686, 0.1686]]],


        [[[0.5333, 0.5333, 0.5333,  ..., 0.5412, 0.5412, 0.5373],
          [0.7176, 0.7059, 0.6980,  ..., 0.7373, 0.7373, 0.7294],
          [0.8314, 0.8314, 0.8314,  ..., 0.8314, 0.8314, 0.8314],
          ...,
          [0.2745, 0.2706, 0.2745,  ..., 0.2627, 0.2745, 0.2745],
          [0.2314, 0.2314, 0.2353,  ..., 0.2118, 0.2157, 0.2275],
          [0.2392, 0.2392, 0.2431,  ..., 0.2353, 0.2353, 0.2392]],

         [[0.4667, 0.4667, 0.4667,  ..., 0.4706, 0.4706, 0.4667],
          [0.6824, 0.6706, 0.6627,  ..., 0.7059, 0.7020, 0.6902],
          [0.8275, 0.8275, 0.8275,  ..., 0.8314, 0.8314, 0.8314],
          ...,
          [0.1490, 0.1490, 0.1490,  ..., 0.1412, 0.1451, 0.1490],
          [0.1373, 0.1373, 0.1373,  ..., 0.1176, 0.1255, 0.1373],
          [0.1490, 0.1490, 0.1529,  ..., 0.1490, 0.1490, 0.1490]],

         [[0.3804, 0.3804, 0.3765,  ..., 0.3922, 0.3882, 0.3843],
          [0.6824, 0.6706, 0.6627,  ..., 0.7098, 0.7059, 0.6902],
          [0.8314, 0.8314, 0.8314,  ..., 0.8314, 0.8314, 0.8314],
          ...,
          [0.0627, 0.0627, 0.0627,  ..., 0.0745, 0.0706, 0.0667],
          [0.0784, 0.0824, 0.0824,  ..., 0.0667, 0.0706, 0.0745],
          [0.0980, 0.1020, 0.1020,  ..., 0.0980, 0.0980, 0.0980]]],


        [[[0.5490, 0.5490, 0.5490,  ..., 0.5490, 0.5490, 0.5490],
          [0.5490, 0.5529, 0.5529,  ..., 0.5529, 0.5529, 0.5490],
          [0.5490, 0.5490, 0.5529,  ..., 0.5451, 0.5490, 0.5490],
          ...,
          [0.4118, 0.4118, 0.4118,  ..., 0.4196, 0.4157, 0.4157],
          [0.4039, 0.4039, 0.4039,  ..., 0.4039, 0.4039, 0.4039],
          [0.4078, 0.4078, 0.4078,  ..., 0.4078, 0.4039, 0.4039]],

         [[0.5098, 0.5098, 0.5098,  ..., 0.5098, 0.5098, 0.5098],
          [0.5176, 0.5176, 0.5176,  ..., 0.5137, 0.5176, 0.5137],
          [0.5137, 0.5176, 0.5216,  ..., 0.5176, 0.5137, 0.5137],
          ...,
          [0.3608, 0.3608, 0.3608,  ..., 0.3686, 0.3647, 0.3647],
          [0.3529, 0.3529, 0.3529,  ..., 0.3490, 0.3529, 0.3529],
          [0.3608, 0.3608, 0.3608,  ..., 0.3569, 0.3608, 0.3569]],

         [[0.5294, 0.5294, 0.5294,  ..., 0.5294, 0.5294, 0.5294],
          [0.5333, 0.5333, 0.5333,  ..., 0.5333, 0.5333, 0.5333],
          [0.5373, 0.5373, 0.5412,  ..., 0.5373, 0.5333, 0.5373],
          ...,
          [0.3725, 0.3725, 0.3725,  ..., 0.3765, 0.3725, 0.3725],
          [0.3608, 0.3569, 0.3569,  ..., 0.3608, 0.3608, 0.3608],
          [0.3569, 0.3569, 0.3608,  ..., 0.3569, 0.3569, 0.3569]]],


        ...,


        [[[0.3176, 0.3176, 0.3176,  ..., 0.3176, 0.3176, 0.3176],
          [0.3176, 0.3176, 0.3176,  ..., 0.3176, 0.3137, 0.3137],
          [0.3137, 0.3137, 0.3176,  ..., 0.3137, 0.3137, 0.3137],
          ...,
          [0.2588, 0.2745, 0.2902,  ..., 0.1961, 0.2431, 0.2510],
          [0.2157, 0.2275, 0.2431,  ..., 0.1412, 0.1647, 0.1961],
          [0.1255, 0.1294, 0.1294,  ..., 0.1176, 0.1176, 0.1216]],

         [[0.2745, 0.2745, 0.2706,  ..., 0.2706, 0.2706, 0.2745],
          [0.2745, 0.2745, 0.2745,  ..., 0.2745, 0.2706, 0.2706],
          [0.2706, 0.2706, 0.2745,  ..., 0.2706, 0.2706, 0.2706],
          ...,
          [0.1647, 0.1804, 0.1961,  ..., 0.1098, 0.1490, 0.1569],
          [0.1373, 0.1490, 0.1569,  ..., 0.0667, 0.0902, 0.1176],
          [0.0627, 0.0706, 0.0706,  ..., 0.0588, 0.0627, 0.0627]],

         [[0.2353, 0.2353, 0.2353,  ..., 0.2353, 0.2353, 0.2353],
          [0.2353, 0.2353, 0.2353,  ..., 0.2353, 0.2314, 0.2314],
          [0.2275, 0.2275, 0.2314,  ..., 0.2275, 0.2275, 0.2275],
          ...,
          [0.1098, 0.1255, 0.1412,  ..., 0.0706, 0.1020, 0.1059],
          [0.0902, 0.0980, 0.1059,  ..., 0.0392, 0.0549, 0.0784],
          [0.0549, 0.0549, 0.0549,  ..., 0.0549, 0.0549, 0.0549]]],


        [[[0.6471, 0.6471, 0.6510,  ..., 0.6549, 0.6510, 0.6510],
          [0.6510, 0.6549, 0.6510,  ..., 0.6431, 0.6431, 0.6431],
          [0.6588, 0.6588, 0.6549,  ..., 0.6667, 0.6667, 0.6627],
          ...,
          [0.0784, 0.0784, 0.0784,  ..., 0.0824, 0.0824, 0.0784],
          [0.0980, 0.0980, 0.1020,  ..., 0.0941, 0.0941, 0.0941],
          [0.2275, 0.2235, 0.2235,  ..., 0.2235, 0.2235, 0.2235]],

         [[0.5333, 0.5333, 0.5373,  ..., 0.5412, 0.5373, 0.5373],
          [0.5373, 0.5412, 0.5373,  ..., 0.5294, 0.5294, 0.5294],
          [0.5451, 0.5451, 0.5412,  ..., 0.5529, 0.5529, 0.5490],
          ...,
          [0.0353, 0.0353, 0.0353,  ..., 0.0392, 0.0392, 0.0392],
          [0.0431, 0.0431, 0.0431,  ..., 0.0392, 0.0353, 0.0392],
          [0.1176, 0.1176, 0.1176,  ..., 0.1176, 0.1176, 0.1176]],

         [[0.4118, 0.4157, 0.4196,  ..., 0.4196, 0.4196, 0.4157],
          [0.4196, 0.4235, 0.4196,  ..., 0.4118, 0.4118, 0.4118],
          [0.4275, 0.4275, 0.4235,  ..., 0.4353, 0.4353, 0.4314],
          ...,
          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0667, 0.0667],
          [0.0667, 0.0667, 0.0667,  ..., 0.0627, 0.0627, 0.0627],
          [0.0902, 0.0863, 0.0863,  ..., 0.0902, 0.0902, 0.0863]]],


        [[[0.3255, 0.3255, 0.3255,  ..., 0.3255, 0.3255, 0.3255],
          [0.3176, 0.3176, 0.3176,  ..., 0.3176, 0.3176, 0.3176],
          [0.3176, 0.3176, 0.3176,  ..., 0.3176, 0.3176, 0.3176],
          ...,
          [0.1216, 0.1216, 0.1176,  ..., 0.1216, 0.1216, 0.1216],
          [0.1216, 0.1216, 0.1176,  ..., 0.1176, 0.1176, 0.1176],
          [0.1176, 0.1176, 0.1176,  ..., 0.1176, 0.1176, 0.1176]],

         [[0.2941, 0.2941, 0.2941,  ..., 0.2980, 0.2980, 0.2941],
          [0.2941, 0.2941, 0.2941,  ..., 0.2980, 0.2941, 0.2941],
          [0.2980, 0.2980, 0.2980,  ..., 0.2980, 0.2941, 0.2941],
          ...,
          [0.0784, 0.0784, 0.0745,  ..., 0.0784, 0.0784, 0.0784],
          [0.0784, 0.0784, 0.0784,  ..., 0.0784, 0.0784, 0.0784],
          [0.0784, 0.0784, 0.0784,  ..., 0.0784, 0.0784, 0.0784]],

         [[0.2706, 0.2706, 0.2706,  ..., 0.2706, 0.2706, 0.2706],
          [0.2706, 0.2706, 0.2706,  ..., 0.2706, 0.2706, 0.2706],
          [0.2706, 0.2745, 0.2745,  ..., 0.2745, 0.2706, 0.2706],
          ...,
          [0.0627, 0.0627, 0.0588,  ..., 0.0627, 0.0627, 0.0588],
          [0.0627, 0.0627, 0.0588,  ..., 0.0588, 0.0588, 0.0588],
          [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588]]]])
tensor([[[[0.3922, 0.3882, 0.3882,  ..., 0.3882, 0.3922, 0.3922],
          [0.3843, 0.3843, 0.3843,  ..., 0.3843, 0.3843, 0.3843],
          [0.3843, 0.3843, 0.3843,  ..., 0.3882, 0.3882, 0.3882],
          ...,
          [0.0784, 0.0784, 0.0784,  ..., 0.0784, 0.0784, 0.0784],
          [0.0941, 0.0980, 0.1020,  ..., 0.0824, 0.0863, 0.0902],
          [0.1098, 0.1137, 0.1137,  ..., 0.1020, 0.1020, 0.1059]],

         [[0.3412, 0.3412, 0.3412,  ..., 0.3412, 0.3412, 0.3412],
          [0.3412, 0.3412, 0.3412,  ..., 0.3412, 0.3412, 0.3412],
          [0.3412, 0.3412, 0.3412,  ..., 0.3412, 0.3412, 0.3412],
          ...,
          [0.0431, 0.0431, 0.0471,  ..., 0.0431, 0.0431, 0.0431],
          [0.0627, 0.0627, 0.0667,  ..., 0.0510, 0.0510, 0.0588],
          [0.0784, 0.0784, 0.0784,  ..., 0.0706, 0.0745, 0.0784]],

         [[0.3137, 0.3137, 0.3137,  ..., 0.3137, 0.3137, 0.3137],
          [0.3137, 0.3137, 0.3137,  ..., 0.3137, 0.3137, 0.3137],
          [0.3137, 0.3137, 0.3137,  ..., 0.3137, 0.3137, 0.3137],
          ...,
          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627],
          [0.0706, 0.0745, 0.0745,  ..., 0.0627, 0.0627, 0.0667],
          [0.0784, 0.0784, 0.0784,  ..., 0.0745, 0.0784, 0.0784]]],


        [[[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],
          [0.5020, 0.4980, 0.5020,  ..., 0.4980, 0.4980, 0.4980],
          [0.4980, 0.5020, 0.5020,  ..., 0.4941, 0.4941, 0.4980],
          ...,
          [0.2196, 0.2196, 0.2392,  ..., 0.3098, 0.2902, 0.2510],
          [0.3725, 0.3686, 0.3569,  ..., 0.4000, 0.3922, 0.3843],
          [0.3882, 0.3882, 0.3882,  ..., 0.3882, 0.3882, 0.3882]],

         [[0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],
          [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],
          [0.4471, 0.4471, 0.4471,  ..., 0.4392, 0.4431, 0.4471],
          ...,
          [0.1098, 0.1020, 0.1255,  ..., 0.1922, 0.1765, 0.1412],
          [0.2471, 0.2392, 0.2314,  ..., 0.2667, 0.2627, 0.2510],
          [0.2549, 0.2549, 0.2549,  ..., 0.2588, 0.2588, 0.2588]],

         [[0.4157, 0.4157, 0.4157,  ..., 0.4157, 0.4157, 0.4157],
          [0.4196, 0.4157, 0.4196,  ..., 0.4157, 0.4157, 0.4157],
          [0.4157, 0.4196, 0.4196,  ..., 0.4078, 0.4118, 0.4157],
          ...,
          [0.0314, 0.0471, 0.0745,  ..., 0.0431, 0.0431, 0.0314],
          [0.0588, 0.0588, 0.0588,  ..., 0.0667, 0.0588, 0.0588],
          [0.0824, 0.0784, 0.0824,  ..., 0.0745, 0.0745, 0.0784]]],


        [[[0.2902, 0.2902, 0.2902,  ..., 0.2902, 0.2902, 0.2902],
          [0.2902, 0.2902, 0.2902,  ..., 0.2902, 0.2902, 0.2902],
          [0.2902, 0.2902, 0.2902,  ..., 0.2902, 0.2902, 0.2902],
          ...,
          [0.0863, 0.0863, 0.0863,  ..., 0.0863, 0.0902, 0.0863],
          [0.0824, 0.0824, 0.0824,  ..., 0.0824, 0.0824, 0.0824],
          [0.0824, 0.0863, 0.0824,  ..., 0.0824, 0.0863, 0.0863]],

         [[0.2431, 0.2431, 0.2431,  ..., 0.2431, 0.2431, 0.2431],
          [0.2431, 0.2431, 0.2431,  ..., 0.2471, 0.2431, 0.2431],
          [0.2431, 0.2392, 0.2392,  ..., 0.2431, 0.2431, 0.2431],
          ...,
          [0.0549, 0.0549, 0.0588,  ..., 0.0588, 0.0588, 0.0549],
          [0.0510, 0.0471, 0.0471,  ..., 0.0510, 0.0510, 0.0510],
          [0.0471, 0.0471, 0.0471,  ..., 0.0471, 0.0471, 0.0471]],

         [[0.1922, 0.1922, 0.1922,  ..., 0.1922, 0.1922, 0.1922],
          [0.1882, 0.1882, 0.1882,  ..., 0.1922, 0.1922, 0.1922],
          [0.1882, 0.1843, 0.1882,  ..., 0.1882, 0.1922, 0.1882],
          ...,
          [0.0588, 0.0588, 0.0549,  ..., 0.0627, 0.0627, 0.0588],
          [0.0471, 0.0431, 0.0431,  ..., 0.0431, 0.0471, 0.0471],
          [0.0353, 0.0392, 0.0353,  ..., 0.0392, 0.0392, 0.0392]]],


        ...,


        [[[0.5137, 0.5137, 0.5137,  ..., 0.5137, 0.5137, 0.5137],
          [0.5176, 0.5137, 0.5137,  ..., 0.5137, 0.5137, 0.5137],
          [0.5137, 0.5137, 0.5137,  ..., 0.5137, 0.5137, 0.5137],
          ...,
          [0.1961, 0.1961, 0.1922,  ..., 0.1882, 0.1882, 0.1922],
          [0.2157, 0.2118, 0.2078,  ..., 0.2196, 0.2196, 0.2196],
          [0.2157, 0.2118, 0.2118,  ..., 0.2157, 0.2157, 0.2157]],

         [[0.4627, 0.4627, 0.4627,  ..., 0.4627, 0.4627, 0.4627],
          [0.4667, 0.4627, 0.4627,  ..., 0.4627, 0.4627, 0.4627],
          [0.4627, 0.4627, 0.4627,  ..., 0.4627, 0.4627, 0.4588],
          ...,
          [0.1255, 0.1216, 0.1216,  ..., 0.1176, 0.1176, 0.1216],
          [0.1412, 0.1373, 0.1333,  ..., 0.1451, 0.1451, 0.1451],
          [0.1882, 0.1843, 0.1843,  ..., 0.1961, 0.1961, 0.1922]],

         [[0.4235, 0.4235, 0.4235,  ..., 0.4235, 0.4235, 0.4235],
          [0.4235, 0.4235, 0.4235,  ..., 0.4235, 0.4235, 0.4235],
          [0.4235, 0.4235, 0.4235,  ..., 0.4235, 0.4235, 0.4196],
          ...,
          [0.0549, 0.0549, 0.0549,  ..., 0.0510, 0.0510, 0.0549],
          [0.0706, 0.0706, 0.0706,  ..., 0.0863, 0.0784, 0.0745],
          [0.1647, 0.1608, 0.1529,  ..., 0.1765, 0.1686, 0.1647]]],


        [[[0.4824, 0.4824, 0.4824,  ..., 0.4824, 0.4824, 0.4824],
          [0.3882, 0.3922, 0.3961,  ..., 0.3804, 0.3804, 0.3843],
          [0.2275, 0.2314, 0.2392,  ..., 0.2196, 0.2196, 0.2235],
          ...,
          [0.2157, 0.2431, 0.2431,  ..., 0.2078, 0.2353, 0.2196],
          [0.1882, 0.2000, 0.2118,  ..., 0.1961, 0.2000, 0.1961],
          [0.1569, 0.1569, 0.1569,  ..., 0.1647, 0.1608, 0.1569]],

         [[0.4902, 0.4902, 0.4902,  ..., 0.4902, 0.4902, 0.4902],
          [0.4157, 0.4196, 0.4235,  ..., 0.4078, 0.4078, 0.4118],
          [0.2510, 0.2588, 0.2627,  ..., 0.2431, 0.2431, 0.2471],
          ...,
          [0.1765, 0.2039, 0.2039,  ..., 0.1529, 0.1882, 0.1765],
          [0.1765, 0.1843, 0.1961,  ..., 0.1843, 0.1882, 0.1843],
          [0.1686, 0.1686, 0.1686,  ..., 0.1765, 0.1725, 0.1686]],

         [[0.4902, 0.4902, 0.4902,  ..., 0.4902, 0.4902, 0.4902],
          [0.4431, 0.4471, 0.4510,  ..., 0.4392, 0.4392, 0.4392],
          [0.3216, 0.3255, 0.3294,  ..., 0.3098, 0.3137, 0.3137],
          ...,
          [0.1725, 0.2000, 0.2039,  ..., 0.1569, 0.1843, 0.1725],
          [0.1961, 0.2039, 0.2118,  ..., 0.2078, 0.2118, 0.2078],
          [0.2078, 0.2078, 0.2078,  ..., 0.2157, 0.2118, 0.2078]]],


        [[[0.2039, 0.2039, 0.2000,  ..., 0.2039, 0.2039, 0.2039],
          [0.2039, 0.2039, 0.2039,  ..., 0.2039, 0.2039, 0.2039],
          [0.2078, 0.2078, 0.2039,  ..., 0.2039, 0.2039, 0.2039],
          ...,
          [0.1961, 0.1961, 0.1961,  ..., 0.1961, 0.1961, 0.1961],
          [0.2039, 0.2039, 0.2039,  ..., 0.2000, 0.2039, 0.2039],
          [0.1922, 0.1882, 0.1922,  ..., 0.1922, 0.1922, 0.1922]],

         [[0.1765, 0.1765, 0.1765,  ..., 0.1765, 0.1765, 0.1765],
          [0.1765, 0.1765, 0.1765,  ..., 0.1765, 0.1765, 0.1765],
          [0.1765, 0.1765, 0.1765,  ..., 0.1765, 0.1725, 0.1765],
          ...,
          [0.1059, 0.1020, 0.1020,  ..., 0.1059, 0.1059, 0.1059],
          [0.1098, 0.1137, 0.1137,  ..., 0.1098, 0.1098, 0.1098],
          [0.1020, 0.1020, 0.1020,  ..., 0.1020, 0.1020, 0.1020]],

         [[0.1529, 0.1529, 0.1490,  ..., 0.1529, 0.1529, 0.1529],
          [0.1490, 0.1490, 0.1490,  ..., 0.1490, 0.1490, 0.1490],
          [0.1490, 0.1490, 0.1490,  ..., 0.1490, 0.1490, 0.1490],
          ...,
          [0.0510, 0.0510, 0.0510,  ..., 0.0549, 0.0510, 0.0510],
          [0.0588, 0.0588, 0.0549,  ..., 0.0549, 0.0549, 0.0549],
          [0.0431, 0.0431, 0.0431,  ..., 0.0471, 0.0471, 0.0471]]]])
tensor([[[[0.2353, 0.2353, 0.2353,  ..., 0.2353, 0.2353, 0.2353],
          [0.2353, 0.2353, 0.2392,  ..., 0.2353, 0.2353, 0.2353],
          [0.2353, 0.2353, 0.2353,  ..., 0.2353, 0.2353, 0.2353],
          ...,
          [0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0314, 0.0314],
          [0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0314, 0.0314],
          [0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0314, 0.0314]],

         [[0.2000, 0.2000, 0.2000,  ..., 0.2000, 0.2000, 0.2000],
          [0.2000, 0.2000, 0.2000,  ..., 0.2000, 0.2000, 0.2000],
          [0.2000, 0.2000, 0.2000,  ..., 0.1961, 0.2000, 0.2000],
          ...,
          [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],
          [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],
          [0.0118, 0.0157, 0.0157,  ..., 0.0118, 0.0118, 0.0118]],

         [[0.1451, 0.1451, 0.1451,  ..., 0.1451, 0.1451, 0.1451],
          [0.1451, 0.1451, 0.1490,  ..., 0.1451, 0.1451, 0.1451],
          [0.1451, 0.1451, 0.1451,  ..., 0.1451, 0.1451, 0.1451],
          ...,
          [0.0039, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],
          [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],
          [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078]]],


        [[[0.3725, 0.3725, 0.3725,  ..., 0.3725, 0.3725, 0.3725],
          [0.3373, 0.3333, 0.3373,  ..., 0.3373, 0.3373, 0.3373],
          [0.4000, 0.4000, 0.3961,  ..., 0.4039, 0.4039, 0.4039],
          ...,
          [0.0627, 0.0706, 0.0745,  ..., 0.0588, 0.0588, 0.0588],
          [0.1059, 0.1059, 0.1098,  ..., 0.1020, 0.1059, 0.1059],
          [0.2353, 0.2392, 0.2392,  ..., 0.2314, 0.2353, 0.2353]],

         [[0.3294, 0.3294, 0.3294,  ..., 0.3255, 0.3255, 0.3294],
          [0.2941, 0.2941, 0.2941,  ..., 0.2941, 0.2941, 0.2941],
          [0.3569, 0.3569, 0.3529,  ..., 0.3608, 0.3608, 0.3608],
          ...,
          [0.0235, 0.0275, 0.0314,  ..., 0.0196, 0.0157, 0.0196],
          [0.0588, 0.0627, 0.0627,  ..., 0.0549, 0.0549, 0.0549],
          [0.1765, 0.1804, 0.1804,  ..., 0.1725, 0.1725, 0.1765]],

         [[0.2000, 0.1961, 0.1961,  ..., 0.2000, 0.2000, 0.2000],
          [0.1725, 0.1686, 0.1686,  ..., 0.1765, 0.1765, 0.1725],
          [0.2353, 0.2353, 0.2353,  ..., 0.2392, 0.2392, 0.2353],
          ...,
          [0.0078, 0.0078, 0.0118,  ..., 0.0039, 0.0078, 0.0078],
          [0.0314, 0.0314, 0.0353,  ..., 0.0275, 0.0314, 0.0314],
          [0.1176, 0.1216, 0.1255,  ..., 0.1176, 0.1176, 0.1176]]],


        [[[0.1882, 0.1882, 0.1882,  ..., 0.1882, 0.1882, 0.1882],
          [0.1882, 0.1882, 0.1882,  ..., 0.1882, 0.1882, 0.1882],
          [0.1882, 0.1882, 0.1882,  ..., 0.1882, 0.1882, 0.1882],
          ...,
          [0.0235, 0.0235, 0.0235,  ..., 0.0235, 0.0235, 0.0235],
          [0.0235, 0.0235, 0.0235,  ..., 0.0196, 0.0235, 0.0235],
          [0.0235, 0.0235, 0.0235,  ..., 0.0235, 0.0235, 0.0235]],

         [[0.1843, 0.1843, 0.1843,  ..., 0.1843, 0.1843, 0.1843],
          [0.1843, 0.1843, 0.1843,  ..., 0.1804, 0.1804, 0.1843],
          [0.1804, 0.1804, 0.1804,  ..., 0.1804, 0.1804, 0.1804],
          ...,
          [0.0196, 0.0196, 0.0196,  ..., 0.0196, 0.0196, 0.0157],
          [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],
          [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157]],

         [[0.1608, 0.1608, 0.1647,  ..., 0.1608, 0.1608, 0.1608],
          [0.1608, 0.1647, 0.1647,  ..., 0.1608, 0.1608, 0.1608],
          [0.1608, 0.1608, 0.1608,  ..., 0.1608, 0.1608, 0.1608],
          ...,
          [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],
          [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],
          [0.0157, 0.0157, 0.0157,  ..., 0.0196, 0.0196, 0.0157]]],


        ...,


        [[[0.2784, 0.2784, 0.2784,  ..., 0.2784, 0.2784, 0.2784],
          [0.2824, 0.2824, 0.2824,  ..., 0.2784, 0.2824, 0.2824],
          [0.2784, 0.2745, 0.2745,  ..., 0.2784, 0.2784, 0.2784],
          ...,
          [0.0863, 0.0863, 0.0863,  ..., 0.0863, 0.0863, 0.0863],
          [0.0706, 0.0706, 0.0706,  ..., 0.0667, 0.0706, 0.0706],
          [0.0667, 0.0667, 0.0667,  ..., 0.0627, 0.0667, 0.0667]],

         [[0.2549, 0.2549, 0.2549,  ..., 0.2549, 0.2549, 0.2549],
          [0.2588, 0.2588, 0.2588,  ..., 0.2549, 0.2549, 0.2549],
          [0.2588, 0.2549, 0.2549,  ..., 0.2549, 0.2549, 0.2588],
          ...,
          [0.0706, 0.0667, 0.0706,  ..., 0.0706, 0.0706, 0.0706],
          [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588],
          [0.0549, 0.0549, 0.0549,  ..., 0.0549, 0.0549, 0.0549]],

         [[0.2275, 0.2314, 0.2275,  ..., 0.2275, 0.2275, 0.2314],
          [0.2353, 0.2353, 0.2314,  ..., 0.2314, 0.2314, 0.2314],
          [0.2353, 0.2314, 0.2314,  ..., 0.2353, 0.2314, 0.2353],
          ...,
          [0.0745, 0.0745, 0.0745,  ..., 0.0745, 0.0745, 0.0706],
          [0.0667, 0.0667, 0.0667,  ..., 0.0627, 0.0667, 0.0667],
          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627]]],


        [[[0.2824, 0.2824, 0.2824,  ..., 0.2784, 0.2824, 0.2824],
          [0.2863, 0.2863, 0.2824,  ..., 0.2824, 0.2863, 0.2863],
          [0.2863, 0.2863, 0.2863,  ..., 0.2863, 0.2863, 0.2863],
          ...,
          [0.1333, 0.1373, 0.1373,  ..., 0.1333, 0.1333, 0.1333],
          [0.1333, 0.1333, 0.1373,  ..., 0.1294, 0.1333, 0.1333],
          [0.1294, 0.1294, 0.1294,  ..., 0.1333, 0.1333, 0.1294]],

         [[0.2431, 0.2471, 0.2471,  ..., 0.2431, 0.2431, 0.2431],
          [0.2510, 0.2510, 0.2471,  ..., 0.2471, 0.2510, 0.2510],
          [0.2510, 0.2510, 0.2510,  ..., 0.2510, 0.2510, 0.2510],
          ...,
          [0.0980, 0.1020, 0.1020,  ..., 0.0980, 0.0980, 0.0980],
          [0.0980, 0.0980, 0.1020,  ..., 0.0941, 0.0980, 0.0980],
          [0.0941, 0.0941, 0.0941,  ..., 0.0980, 0.0980, 0.0941]],

         [[0.1804, 0.1804, 0.1804,  ..., 0.1804, 0.1804, 0.1804],
          [0.1882, 0.1882, 0.1843,  ..., 0.1843, 0.1882, 0.1882],
          [0.1882, 0.1922, 0.1922,  ..., 0.1882, 0.1922, 0.1882],
          ...,
          [0.0784, 0.0784, 0.0824,  ..., 0.0745, 0.0745, 0.0745],
          [0.0784, 0.0784, 0.0824,  ..., 0.0745, 0.0784, 0.0784],
          [0.0745, 0.0745, 0.0745,  ..., 0.0784, 0.0784, 0.0745]]],


        [[[0.3765, 0.3765, 0.3765,  ..., 0.3765, 0.3765, 0.3765],
          [0.3804, 0.3804, 0.3804,  ..., 0.3804, 0.3804, 0.3804],
          [0.3882, 0.3882, 0.3922,  ..., 0.3922, 0.3882, 0.3882],
          ...,
          [0.3490, 0.3451, 0.3451,  ..., 0.3451, 0.3451, 0.3490],
          [0.2000, 0.1961, 0.1922,  ..., 0.2078, 0.2039, 0.2000],
          [0.1373, 0.1333, 0.1294,  ..., 0.1451, 0.1451, 0.1412]],

         [[0.3451, 0.3451, 0.3451,  ..., 0.3451, 0.3451, 0.3451],
          [0.3529, 0.3490, 0.3490,  ..., 0.3529, 0.3529, 0.3529],
          [0.3608, 0.3608, 0.3647,  ..., 0.3647, 0.3608, 0.3608],
          ...,
          [0.3137, 0.3137, 0.3137,  ..., 0.3137, 0.3137, 0.3176],
          [0.1529, 0.1490, 0.1490,  ..., 0.1608, 0.1529, 0.1490],
          [0.1098, 0.1059, 0.1020,  ..., 0.1176, 0.1176, 0.1098]],

         [[0.2902, 0.2902, 0.2902,  ..., 0.2902, 0.2902, 0.2902],
          [0.2941, 0.2902, 0.2902,  ..., 0.2941, 0.2941, 0.2941],
          [0.3059, 0.3059, 0.3059,  ..., 0.3059, 0.3020, 0.3020],
          ...,
          [0.2627, 0.2588, 0.2588,  ..., 0.2627, 0.2627, 0.2667],
          [0.1216, 0.1137, 0.1137,  ..., 0.1294, 0.1216, 0.1216],
          [0.0941, 0.0941, 0.0863,  ..., 0.1020, 0.1020, 0.0980]]]])
tensor([[[[0.4549, 0.4549, 0.4549,  ..., 0.4549, 0.4549, 0.4549],
          [0.4549, 0.4549, 0.4549,  ..., 0.4549, 0.4549, 0.4549],
          [0.4549, 0.4549, 0.4549,  ..., 0.4549, 0.4549, 0.4549],
          ...,
          [0.4353, 0.4431, 0.4471,  ..., 0.4314, 0.4392, 0.4353],
          [0.4353, 0.4431, 0.4471,  ..., 0.4196, 0.4196, 0.4235],
          [0.4275, 0.4275, 0.4235,  ..., 0.4196, 0.4196, 0.4235]],

         [[0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],
          [0.4000, 0.4000, 0.3961,  ..., 0.4000, 0.4000, 0.4000],
          [0.3961, 0.3961, 0.3961,  ..., 0.3961, 0.3961, 0.3961],
          ...,
          [0.3176, 0.3294, 0.3294,  ..., 0.3176, 0.3216, 0.3176],
          [0.3176, 0.3294, 0.3333,  ..., 0.2980, 0.2980, 0.3059],
          [0.3098, 0.3098, 0.3098,  ..., 0.2980, 0.2980, 0.3059]],

         [[0.3216, 0.3216, 0.3216,  ..., 0.3216, 0.3216, 0.3216],
          [0.3216, 0.3216, 0.3176,  ..., 0.3216, 0.3216, 0.3216],
          [0.3176, 0.3176, 0.3176,  ..., 0.3176, 0.3176, 0.3176],
          ...,
          [0.1765, 0.1882, 0.1922,  ..., 0.1765, 0.1804, 0.1804],
          [0.1843, 0.1882, 0.1882,  ..., 0.1608, 0.1608, 0.1686],
          [0.1765, 0.1725, 0.1725,  ..., 0.1686, 0.1686, 0.1725]]],


        [[[0.7098, 0.7098, 0.7098,  ..., 0.7059, 0.7059, 0.7098],
          [0.6039, 0.6039, 0.6039,  ..., 0.6000, 0.6039, 0.6000],
          [0.5490, 0.5490, 0.5490,  ..., 0.5490, 0.5490, 0.5490],
          ...,
          [0.1529, 0.1608, 0.1608,  ..., 0.1490, 0.1529, 0.1490],
          [0.0510, 0.0549, 0.0588,  ..., 0.0549, 0.0549, 0.0510],
          [0.0863, 0.0863, 0.0863,  ..., 0.0824, 0.0824, 0.0863]],

         [[0.6824, 0.6784, 0.6824,  ..., 0.6784, 0.6784, 0.6784],
          [0.5882, 0.5882, 0.5882,  ..., 0.5882, 0.5882, 0.5882],
          [0.5333, 0.5333, 0.5333,  ..., 0.5333, 0.5333, 0.5333],
          ...,
          [0.0980, 0.1020, 0.1059,  ..., 0.0902, 0.0980, 0.0980],
          [0.0000, 0.0039, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0314, 0.0314, 0.0314,  ..., 0.0275, 0.0275, 0.0314]],

         [[0.7216, 0.7216, 0.7255,  ..., 0.7176, 0.7216, 0.7216],
          [0.5647, 0.5725, 0.5725,  ..., 0.5647, 0.5686, 0.5686],
          [0.4902, 0.4902, 0.4863,  ..., 0.4863, 0.4863, 0.4902],
          ...,
          [0.0706, 0.0745, 0.0745,  ..., 0.0627, 0.0745, 0.0706],
          [0.0118, 0.0118, 0.0118,  ..., 0.0078, 0.0118, 0.0078],
          [0.0275, 0.0235, 0.0235,  ..., 0.0235, 0.0235, 0.0235]]],


        [[[0.5412, 0.5412, 0.5412,  ..., 0.5451, 0.5451, 0.5451],
          [0.5373, 0.5373, 0.5412,  ..., 0.5333, 0.5373, 0.5373],
          [0.5490, 0.5490, 0.5490,  ..., 0.5451, 0.5451, 0.5451],
          ...,
          [0.3294, 0.3255, 0.3294,  ..., 0.3216, 0.3255, 0.3255],
          [0.3373, 0.3373, 0.3373,  ..., 0.3176, 0.3216, 0.3333],
          [0.2980, 0.2941, 0.2941,  ..., 0.2980, 0.2980, 0.2980]],

         [[0.4745, 0.4706, 0.4706,  ..., 0.4745, 0.4745, 0.4745],
          [0.4667, 0.4667, 0.4667,  ..., 0.4627, 0.4627, 0.4667],
          [0.4824, 0.4824, 0.4824,  ..., 0.4784, 0.4824, 0.4824],
          ...,
          [0.2549, 0.2510, 0.2549,  ..., 0.2510, 0.2510, 0.2549],
          [0.2667, 0.2667, 0.2667,  ..., 0.2471, 0.2549, 0.2627],
          [0.2275, 0.2235, 0.2196,  ..., 0.2314, 0.2314, 0.2314]],

         [[0.4039, 0.4039, 0.4039,  ..., 0.4039, 0.4039, 0.4039],
          [0.3922, 0.3922, 0.3922,  ..., 0.3882, 0.3882, 0.3922],
          [0.3961, 0.3961, 0.3961,  ..., 0.3922, 0.3922, 0.3961],
          ...,
          [0.1961, 0.1961, 0.2000,  ..., 0.1961, 0.1922, 0.1961],
          [0.2118, 0.2118, 0.2157,  ..., 0.1922, 0.1961, 0.2078],
          [0.1804, 0.1804, 0.1804,  ..., 0.1843, 0.1843, 0.1804]]],


        ...,


        [[[0.4392, 0.4353, 0.4353,  ..., 0.4392, 0.4392, 0.4392],
          [0.4353, 0.4353, 0.4353,  ..., 0.4353, 0.4353, 0.4353],
          [0.4353, 0.4353, 0.4353,  ..., 0.4353, 0.4353, 0.4353],
          ...,
          [0.1020, 0.1020, 0.1020,  ..., 0.1020, 0.1020, 0.1020],
          [0.1216, 0.1255, 0.1294,  ..., 0.1137, 0.1176, 0.1216],
          [0.1098, 0.1137, 0.1176,  ..., 0.1059, 0.1098, 0.1098]],

         [[0.4118, 0.4118, 0.4118,  ..., 0.4118, 0.4118, 0.4118],
          [0.4118, 0.4118, 0.4118,  ..., 0.4118, 0.4118, 0.4118],
          [0.4118, 0.4118, 0.4118,  ..., 0.4118, 0.4118, 0.4118],
          ...,
          [0.0392, 0.0392, 0.0392,  ..., 0.0392, 0.0392, 0.0392],
          [0.0667, 0.0706, 0.0706,  ..., 0.0588, 0.0627, 0.0667],
          [0.0627, 0.0667, 0.0667,  ..., 0.0549, 0.0549, 0.0627]],

         [[0.3804, 0.3765, 0.3765,  ..., 0.3804, 0.3804, 0.3804],
          [0.3804, 0.3765, 0.3765,  ..., 0.3804, 0.3804, 0.3804],
          [0.3804, 0.3765, 0.3765,  ..., 0.3804, 0.3804, 0.3765],
          ...,
          [0.0471, 0.0510, 0.0510,  ..., 0.0510, 0.0510, 0.0471],
          [0.0706, 0.0745, 0.0745,  ..., 0.0627, 0.0667, 0.0667],
          [0.0588, 0.0588, 0.0627,  ..., 0.0549, 0.0549, 0.0549]]],


        [[[0.4667, 0.4627, 0.4627,  ..., 0.4706, 0.4706, 0.4706],
          [0.4627, 0.4627, 0.4627,  ..., 0.4824, 0.4824, 0.4706],
          [0.4784, 0.4667, 0.4706,  ..., 0.4824, 0.4824, 0.4824],
          ...,
          [0.0784, 0.0745, 0.0745,  ..., 0.0745, 0.0745, 0.0784],
          [0.0902, 0.0902, 0.0863,  ..., 0.0902, 0.0902, 0.0863],
          [0.1098, 0.1098, 0.1098,  ..., 0.1098, 0.1137, 0.1137]],

         [[0.4549, 0.4510, 0.4471,  ..., 0.4588, 0.4588, 0.4588],
          [0.4510, 0.4471, 0.4549,  ..., 0.4667, 0.4667, 0.4627],
          [0.4667, 0.4549, 0.4627,  ..., 0.4667, 0.4667, 0.4667],
          ...,
          [0.0510, 0.0510, 0.0510,  ..., 0.0510, 0.0510, 0.0510],
          [0.0549, 0.0549, 0.0549,  ..., 0.0549, 0.0549, 0.0549],
          [0.0745, 0.0784, 0.0784,  ..., 0.0745, 0.0784, 0.0784]],

         [[0.4431, 0.4431, 0.4392,  ..., 0.4471, 0.4471, 0.4471],
          [0.4392, 0.4353, 0.4431,  ..., 0.4588, 0.4588, 0.4510],
          [0.4588, 0.4431, 0.4510,  ..., 0.4588, 0.4588, 0.4588],
          ...,
          [0.0471, 0.0471, 0.0431,  ..., 0.0431, 0.0431, 0.0471],
          [0.0510, 0.0510, 0.0471,  ..., 0.0510, 0.0510, 0.0471],
          [0.0627, 0.0627, 0.0627,  ..., 0.0627, 0.0627, 0.0627]]],


        [[[0.3686, 0.3686, 0.3686,  ..., 0.3686, 0.3686, 0.3686],
          [0.3686, 0.3686, 0.3686,  ..., 0.3686, 0.3686, 0.3686],
          [0.3647, 0.3686, 0.3686,  ..., 0.3647, 0.3647, 0.3608],
          ...,
          [0.0471, 0.0471, 0.0471,  ..., 0.0510, 0.0471, 0.0471],
          [0.0431, 0.0431, 0.0392,  ..., 0.0431, 0.0431, 0.0431],
          [0.0392, 0.0392, 0.0392,  ..., 0.0392, 0.0392, 0.0392]],

         [[0.2902, 0.2902, 0.2902,  ..., 0.2902, 0.2902, 0.2902],
          [0.2902, 0.2902, 0.2863,  ..., 0.2863, 0.2863, 0.2902],
          [0.2863, 0.2863, 0.2863,  ..., 0.2863, 0.2863, 0.2824],
          ...,
          [0.0196, 0.0196, 0.0196,  ..., 0.0196, 0.0196, 0.0196],
          [0.0157, 0.0157, 0.0118,  ..., 0.0157, 0.0157, 0.0157],
          [0.0157, 0.0157, 0.0118,  ..., 0.0118, 0.0157, 0.0118]],

         [[0.2353, 0.2353, 0.2353,  ..., 0.2353, 0.2353, 0.2353],
          [0.2353, 0.2353, 0.2353,  ..., 0.2353, 0.2353, 0.2353],
          [0.2314, 0.2353, 0.2353,  ..., 0.2314, 0.2314, 0.2275],
          ...,
          [0.0078, 0.0078, 0.0078,  ..., 0.0118, 0.0118, 0.0078],
          [0.0078, 0.0039, 0.0039,  ..., 0.0039, 0.0078, 0.0078],
          [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078]]]])
tensor([[[[0.2588, 0.2588, 0.2588,  ..., 0.2588, 0.2588, 0.2588],
          [0.2549, 0.2588, 0.2588,  ..., 0.2549, 0.2549, 0.2549],
          [0.2549, 0.2549, 0.2549,  ..., 0.2549, 0.2549, 0.2549],
          ...,
          [0.0824, 0.0824, 0.0824,  ..., 0.0863, 0.0863, 0.0863],
          [0.1098, 0.1098, 0.1098,  ..., 0.1098, 0.1098, 0.1059],
          [0.0667, 0.0667, 0.0667,  ..., 0.0667, 0.0667, 0.0667]],

         [[0.2353, 0.2353, 0.2353,  ..., 0.2353, 0.2353, 0.2353],
          [0.2392, 0.2392, 0.2392,  ..., 0.2353, 0.2353, 0.2353],
          [0.2392, 0.2392, 0.2392,  ..., 0.2392, 0.2392, 0.2392],
          ...,
          [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0627, 0.0627],
          [0.0824, 0.0824, 0.0824,  ..., 0.0824, 0.0824, 0.0824],
          [0.0431, 0.0431, 0.0431,  ..., 0.0392, 0.0431, 0.0431]],

         [[0.2000, 0.2000, 0.2000,  ..., 0.2000, 0.2000, 0.2000],
          [0.2000, 0.2039, 0.2039,  ..., 0.2000, 0.2000, 0.2000],
          [0.2039, 0.2039, 0.2039,  ..., 0.2000, 0.2000, 0.2039],
          ...,
          [0.0392, 0.0392, 0.0392,  ..., 0.0431, 0.0471, 0.0431],
          [0.0549, 0.0549, 0.0549,  ..., 0.0549, 0.0549, 0.0549],
          [0.0235, 0.0235, 0.0235,  ..., 0.0235, 0.0235, 0.0235]]],


        [[[0.4745, 0.4745, 0.4745,  ..., 0.4745, 0.4745, 0.4745],
          [0.4588, 0.4627, 0.4627,  ..., 0.4627, 0.4627, 0.4588],
          [0.4471, 0.4471, 0.4471,  ..., 0.4510, 0.4510, 0.4471],
          ...,
          [0.0667, 0.0627, 0.0667,  ..., 0.0667, 0.0667, 0.0667],
          [0.0706, 0.0706, 0.0706,  ..., 0.0667, 0.0706, 0.0667],
          [0.0745, 0.0745, 0.0745,  ..., 0.0745, 0.0745, 0.0745]],

         [[0.4118, 0.4118, 0.4118,  ..., 0.4118, 0.4118, 0.4118],
          [0.4039, 0.4078, 0.4078,  ..., 0.4078, 0.4078, 0.4039],
          [0.3922, 0.3922, 0.3922,  ..., 0.3961, 0.3961, 0.3922],
          ...,
          [0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0314, 0.0314],
          [0.0353, 0.0353, 0.0353,  ..., 0.0314, 0.0353, 0.0353],
          [0.0353, 0.0353, 0.0314,  ..., 0.0353, 0.0353, 0.0353]],

         [[0.2980, 0.2980, 0.2980,  ..., 0.2980, 0.2980, 0.2980],
          [0.2824, 0.2863, 0.2863,  ..., 0.2902, 0.2902, 0.2863],
          [0.2667, 0.2667, 0.2667,  ..., 0.2784, 0.2706, 0.2667],
          ...,
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0039, 0.0039, 0.0039,  ..., 0.0000, 0.0039, 0.0039]]],


        [[[0.4235, 0.4196, 0.4196,  ..., 0.4235, 0.4235, 0.4235],
          [0.4196, 0.4196, 0.4196,  ..., 0.4196, 0.4196, 0.4196],
          [0.4196, 0.4196, 0.4196,  ..., 0.4196, 0.4196, 0.4196],
          ...,
          [0.0706, 0.0706, 0.0706,  ..., 0.0627, 0.0667, 0.0667],
          [0.0667, 0.0667, 0.0667,  ..., 0.0667, 0.0667, 0.0627],
          [0.0706, 0.0706, 0.0706,  ..., 0.0667, 0.0667, 0.0667]],

         [[0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],
          [0.4000, 0.4039, 0.4000,  ..., 0.4000, 0.4039, 0.4039],
          [0.4039, 0.4039, 0.4039,  ..., 0.4039, 0.4039, 0.4039],
          ...,
          [0.0510, 0.0510, 0.0510,  ..., 0.0471, 0.0471, 0.0510],
          [0.0471, 0.0471, 0.0471,  ..., 0.0471, 0.0471, 0.0471],
          [0.0510, 0.0510, 0.0510,  ..., 0.0510, 0.0471, 0.0471]],

         [[0.3843, 0.3843, 0.3804,  ..., 0.3843, 0.3843, 0.3843],
          [0.3882, 0.3882, 0.3882,  ..., 0.3882, 0.3882, 0.3882],
          [0.3922, 0.3922, 0.3922,  ..., 0.3922, 0.3922, 0.3961],
          ...,
          [0.0510, 0.0549, 0.0549,  ..., 0.0431, 0.0471, 0.0471],
          [0.0471, 0.0471, 0.0471,  ..., 0.0471, 0.0471, 0.0431],
          [0.0510, 0.0510, 0.0510,  ..., 0.0471, 0.0471, 0.0471]]],


        ...,


        [[[0.2118, 0.2118, 0.2118,  ..., 0.2118, 0.2118, 0.2118],
          [0.2118, 0.2118, 0.2118,  ..., 0.2118, 0.2118, 0.2118],
          [0.2118, 0.2157, 0.2157,  ..., 0.2118, 0.2118, 0.2157],
          ...,
          [0.1922, 0.1882, 0.1882,  ..., 0.1843, 0.1843, 0.1843],
          [0.1529, 0.1569, 0.1529,  ..., 0.1451, 0.1451, 0.1490],
          [0.0941, 0.1020, 0.1137,  ..., 0.0784, 0.0784, 0.0863]],

         [[0.1922, 0.1922, 0.1922,  ..., 0.1922, 0.1922, 0.1922],
          [0.1922, 0.1922, 0.1922,  ..., 0.1922, 0.1922, 0.1922],
          [0.1922, 0.1922, 0.1922,  ..., 0.1922, 0.1922, 0.1922],
          ...,
          [0.1490, 0.1490, 0.1451,  ..., 0.1412, 0.1412, 0.1451],
          [0.1216, 0.1216, 0.1216,  ..., 0.1137, 0.1098, 0.1137],
          [0.0667, 0.0745, 0.0863,  ..., 0.0471, 0.0510, 0.0588]],

         [[0.1686, 0.1647, 0.1686,  ..., 0.1647, 0.1647, 0.1647],
          [0.1725, 0.1725, 0.1725,  ..., 0.1647, 0.1686, 0.1686],
          [0.1686, 0.1725, 0.1725,  ..., 0.1686, 0.1686, 0.1725],
          ...,
          [0.1176, 0.1137, 0.1137,  ..., 0.1098, 0.1098, 0.1137],
          [0.1020, 0.1020, 0.0980,  ..., 0.0941, 0.0902, 0.0941],
          [0.0667, 0.0745, 0.0824,  ..., 0.0510, 0.0510, 0.0588]]],


        [[[0.4039, 0.4039, 0.4039,  ..., 0.4039, 0.4039, 0.4039],
          [0.4039, 0.4039, 0.4039,  ..., 0.4039, 0.4039, 0.4039],
          [0.4039, 0.4039, 0.4039,  ..., 0.4039, 0.4039, 0.4039],
          ...,
          [0.0902, 0.0863, 0.0863,  ..., 0.0941, 0.0941, 0.0941],
          [0.0745, 0.0784, 0.0824,  ..., 0.0588, 0.0667, 0.0667],
          [0.0745, 0.0745, 0.0745,  ..., 0.0745, 0.0745, 0.0745]],

         [[0.3490, 0.3490, 0.3490,  ..., 0.3490, 0.3451, 0.3490],
          [0.3490, 0.3490, 0.3490,  ..., 0.3490, 0.3490, 0.3490],
          [0.3490, 0.3490, 0.3490,  ..., 0.3490, 0.3490, 0.3490],
          ...,
          [0.0510, 0.0471, 0.0431,  ..., 0.0510, 0.0549, 0.0549],
          [0.0431, 0.0431, 0.0471,  ..., 0.0314, 0.0353, 0.0431],
          [0.0392, 0.0392, 0.0353,  ..., 0.0392, 0.0392, 0.0392]],

         [[0.2941, 0.2941, 0.2941,  ..., 0.2941, 0.2902, 0.2941],
          [0.2941, 0.2941, 0.2941,  ..., 0.2941, 0.2980, 0.2941],
          [0.2941, 0.2941, 0.2980,  ..., 0.2980, 0.2980, 0.2941],
          ...,
          [0.0353, 0.0353, 0.0314,  ..., 0.0314, 0.0353, 0.0353],
          [0.0353, 0.0392, 0.0392,  ..., 0.0235, 0.0275, 0.0314],
          [0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0314, 0.0314]]],


        [[[0.3137, 0.3137, 0.3137,  ..., 0.3137, 0.3137, 0.3137],
          [0.3137, 0.3176, 0.3176,  ..., 0.3176, 0.3137, 0.3137],
          [0.3176, 0.3176, 0.3176,  ..., 0.3176, 0.3137, 0.3176],
          ...,
          [0.1020, 0.1059, 0.1098,  ..., 0.0902, 0.0902, 0.0941],
          [0.0706, 0.0706, 0.0706,  ..., 0.0706, 0.0706, 0.0706],
          [0.0549, 0.0588, 0.0549,  ..., 0.0588, 0.0588, 0.0549]],

         [[0.3059, 0.3059, 0.3059,  ..., 0.3059, 0.3059, 0.3059],
          [0.3059, 0.3098, 0.3098,  ..., 0.3098, 0.3059, 0.3059],
          [0.3098, 0.3098, 0.3098,  ..., 0.3098, 0.3059, 0.3098],
          ...,
          [0.0745, 0.0745, 0.0824,  ..., 0.0627, 0.0667, 0.0706],
          [0.0510, 0.0471, 0.0510,  ..., 0.0549, 0.0549, 0.0510],
          [0.0392, 0.0353, 0.0353,  ..., 0.0431, 0.0392, 0.0392]],

         [[0.2784, 0.2784, 0.2784,  ..., 0.2784, 0.2784, 0.2784],
          [0.2784, 0.2824, 0.2824,  ..., 0.2824, 0.2784, 0.2784],
          [0.2824, 0.2824, 0.2824,  ..., 0.2824, 0.2784, 0.2824],
          ...,
          [0.0745, 0.0745, 0.0745,  ..., 0.0706, 0.0706, 0.0706],
          [0.0510, 0.0510, 0.0510,  ..., 0.0510, 0.0510, 0.0510],
          [0.0392, 0.0392, 0.0392,  ..., 0.0431, 0.0392, 0.0392]]]])
tensor([[[[0.2784, 0.2784, 0.2745,  ..., 0.2784, 0.2784, 0.2784],
          [0.2980, 0.2941, 0.2980,  ..., 0.2980, 0.2980, 0.2980],
          [0.2980, 0.2980, 0.2980,  ..., 0.2980, 0.2980, 0.2980],
          ...,
          [0.0824, 0.0824, 0.0863,  ..., 0.0902, 0.0863, 0.0863],
          [0.0745, 0.0745, 0.0784,  ..., 0.0863, 0.0824, 0.0784],
          [0.0745, 0.0706, 0.0706,  ..., 0.0745, 0.0745, 0.0745]],

         [[0.2353, 0.2353, 0.2314,  ..., 0.2353, 0.2353, 0.2353],
          [0.2510, 0.2510, 0.2510,  ..., 0.2510, 0.2510, 0.2510],
          [0.2510, 0.2510, 0.2510,  ..., 0.2510, 0.2510, 0.2510],
          ...,
          [0.0471, 0.0471, 0.0510,  ..., 0.0588, 0.0549, 0.0510],
          [0.0431, 0.0431, 0.0431,  ..., 0.0510, 0.0471, 0.0471],
          [0.0431, 0.0431, 0.0431,  ..., 0.0431, 0.0431, 0.0431]],

         [[0.1686, 0.1686, 0.1686,  ..., 0.1686, 0.1686, 0.1686],
          [0.1843, 0.1843, 0.1843,  ..., 0.1843, 0.1843, 0.1843],
          [0.1843, 0.1843, 0.1843,  ..., 0.1843, 0.1843, 0.1843],
          ...,
          [0.0314, 0.0314, 0.0353,  ..., 0.0392, 0.0353, 0.0353],
          [0.0235, 0.0275, 0.0275,  ..., 0.0314, 0.0275, 0.0275],
          [0.0275, 0.0275, 0.0275,  ..., 0.0275, 0.0275, 0.0275]]],


        [[[0.2510, 0.2471, 0.2471,  ..., 0.2549, 0.2510, 0.2510],
          [0.2510, 0.2510, 0.2510,  ..., 0.2510, 0.2471, 0.2471],
          [0.2471, 0.2471, 0.2510,  ..., 0.2510, 0.2510, 0.2471],
          ...,
          [0.0588, 0.0588, 0.0549,  ..., 0.0549, 0.0510, 0.0549],
          [0.0588, 0.0588, 0.0588,  ..., 0.0549, 0.0588, 0.0588],
          [0.0510, 0.0510, 0.0510,  ..., 0.0471, 0.0510, 0.0510]],

         [[0.2157, 0.2157, 0.2157,  ..., 0.2196, 0.2196, 0.2157],
          [0.2157, 0.2157, 0.2157,  ..., 0.2157, 0.2118, 0.2118],
          [0.2118, 0.2118, 0.2157,  ..., 0.2196, 0.2157, 0.2118],
          ...,
          [0.0353, 0.0314, 0.0314,  ..., 0.0314, 0.0314, 0.0314],
          [0.0353, 0.0353, 0.0353,  ..., 0.0314, 0.0353, 0.0353],
          [0.0275, 0.0275, 0.0275,  ..., 0.0275, 0.0275, 0.0275]],

         [[0.1647, 0.1608, 0.1608,  ..., 0.1686, 0.1647, 0.1647],
          [0.1608, 0.1647, 0.1647,  ..., 0.1647, 0.1608, 0.1608],
          [0.1647, 0.1647, 0.1647,  ..., 0.1647, 0.1647, 0.1647],
          ...,
          [0.0196, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],
          [0.0196, 0.0196, 0.0196,  ..., 0.0157, 0.0196, 0.0196],
          [0.0118, 0.0118, 0.0157,  ..., 0.0118, 0.0118, 0.0118]]],


        [[[0.2000, 0.2039, 0.2039,  ..., 0.2000, 0.2000, 0.2000],
          [0.2000, 0.2000, 0.2000,  ..., 0.2000, 0.2000, 0.2000],
          [0.2000, 0.2000, 0.2000,  ..., 0.1961, 0.2000, 0.2000],
          ...,
          [0.0510, 0.0431, 0.0353,  ..., 0.0784, 0.0706, 0.0588],
          [0.0745, 0.0627, 0.0471,  ..., 0.0902, 0.0824, 0.0784],
          [0.0118, 0.0118, 0.0157,  ..., 0.0118, 0.0118, 0.0118]],

         [[0.1882, 0.1882, 0.1882,  ..., 0.1882, 0.1882, 0.1882],
          [0.1843, 0.1843, 0.1843,  ..., 0.1843, 0.1843, 0.1843],
          [0.1843, 0.1843, 0.1843,  ..., 0.1843, 0.1843, 0.1843],
          ...,
          [0.0431, 0.0314, 0.0235,  ..., 0.0627, 0.0549, 0.0471],
          [0.0549, 0.0431, 0.0235,  ..., 0.0627, 0.0588, 0.0549],
          [0.0000, 0.0000, 0.0039,  ..., 0.0000, 0.0000, 0.0000]],

         [[0.1725, 0.1725, 0.1725,  ..., 0.1725, 0.1725, 0.1725],
          [0.1686, 0.1686, 0.1686,  ..., 0.1686, 0.1686, 0.1686],
          [0.1686, 0.1686, 0.1686,  ..., 0.1686, 0.1686, 0.1686],
          ...,
          [0.0353, 0.0275, 0.0157,  ..., 0.0588, 0.0510, 0.0392],
          [0.0431, 0.0353, 0.0235,  ..., 0.0431, 0.0431, 0.0431],
          [0.0000, 0.0000, 0.0039,  ..., 0.0000, 0.0039, 0.0000]]],


        ...,


        [[[0.3686, 0.3686, 0.3647,  ..., 0.3647, 0.3647, 0.3647],
          [0.3490, 0.3490, 0.3490,  ..., 0.3569, 0.3529, 0.3529],
          [0.3569, 0.3529, 0.3529,  ..., 0.3608, 0.3608, 0.3569],
          ...,
          [0.1098, 0.1373, 0.1765,  ..., 0.1412, 0.1098, 0.1020],
          [0.2235, 0.1843, 0.1490,  ..., 0.3412, 0.3098, 0.2627],
          [0.3529, 0.3412, 0.3333,  ..., 0.3765, 0.3686, 0.3608]],

         [[0.3451, 0.3451, 0.3451,  ..., 0.3451, 0.3451, 0.3451],
          [0.3294, 0.3294, 0.3294,  ..., 0.3333, 0.3333, 0.3294],
          [0.3373, 0.3333, 0.3294,  ..., 0.3412, 0.3373, 0.3373],
          ...,
          [0.0353, 0.0706, 0.1137,  ..., 0.0353, 0.0118, 0.0196],
          [0.0941, 0.0588, 0.0353,  ..., 0.2157, 0.1804, 0.1333],
          [0.2353, 0.2235, 0.2157,  ..., 0.2667, 0.2588, 0.2471]],

         [[0.3137, 0.3137, 0.3098,  ..., 0.3098, 0.3098, 0.3098],
          [0.2980, 0.2941, 0.2941,  ..., 0.3020, 0.3020, 0.3020],
          [0.3098, 0.3059, 0.3020,  ..., 0.3098, 0.3098, 0.3098],
          ...,
          [0.0902, 0.1255, 0.1647,  ..., 0.0196, 0.0275, 0.0588],
          [0.0431, 0.0314, 0.0275,  ..., 0.1098, 0.0902, 0.0627],
          [0.1255, 0.1216, 0.1176,  ..., 0.1490, 0.1412, 0.1333]]],


        [[[0.4039, 0.4039, 0.4039,  ..., 0.4000, 0.4000, 0.4039],
          [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],
          [0.3961, 0.3961, 0.3961,  ..., 0.4000, 0.3961, 0.3922],
          ...,
          [0.0471, 0.0431, 0.0431,  ..., 0.0471, 0.0431, 0.0471],
          [0.0471, 0.0471, 0.0471,  ..., 0.0431, 0.0471, 0.0471],
          [0.0549, 0.0549, 0.0549,  ..., 0.0510, 0.0549, 0.0549]],

         [[0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],
          [0.3922, 0.3922, 0.3922,  ..., 0.3961, 0.3922, 0.3922],
          [0.3922, 0.3922, 0.3922,  ..., 0.3961, 0.3922, 0.3922],
          ...,
          [0.0353, 0.0314, 0.0314,  ..., 0.0353, 0.0314, 0.0353],
          [0.0353, 0.0353, 0.0353,  ..., 0.0353, 0.0353, 0.0353],
          [0.0353, 0.0353, 0.0353,  ..., 0.0353, 0.0353, 0.0353]],

         [[0.3765, 0.3765, 0.3765,  ..., 0.3765, 0.3765, 0.3765],
          [0.3765, 0.3765, 0.3765,  ..., 0.3765, 0.3765, 0.3765],
          [0.3725, 0.3725, 0.3725,  ..., 0.3765, 0.3765, 0.3725],
          ...,
          [0.0314, 0.0314, 0.0275,  ..., 0.0353, 0.0314, 0.0353],
          [0.0353, 0.0353, 0.0314,  ..., 0.0314, 0.0314, 0.0314],
          [0.0392, 0.0392, 0.0392,  ..., 0.0353, 0.0353, 0.0353]]],


        [[[0.1961, 0.1961, 0.1961,  ..., 0.1961, 0.1961, 0.1961],
          [0.1961, 0.1961, 0.1961,  ..., 0.1961, 0.1961, 0.1961],
          [0.1961, 0.1961, 0.1961,  ..., 0.1961, 0.1961, 0.1961],
          ...,
          [0.1216, 0.1216, 0.1373,  ..., 0.1216, 0.1255, 0.1216],
          [0.0941, 0.0902, 0.0863,  ..., 0.0980, 0.0980, 0.0941],
          [0.0902, 0.0863, 0.0824,  ..., 0.0941, 0.0902, 0.0902]],

         [[0.1647, 0.1647, 0.1647,  ..., 0.1647, 0.1647, 0.1647],
          [0.1647, 0.1647, 0.1647,  ..., 0.1647, 0.1647, 0.1647],
          [0.1647, 0.1647, 0.1647,  ..., 0.1647, 0.1647, 0.1647],
          ...,
          [0.0706, 0.0706, 0.0824,  ..., 0.0784, 0.0784, 0.0745],
          [0.0667, 0.0588, 0.0549,  ..., 0.0667, 0.0667, 0.0667],
          [0.0588, 0.0549, 0.0549,  ..., 0.0588, 0.0588, 0.0588]],

         [[0.1176, 0.1176, 0.1176,  ..., 0.1176, 0.1176, 0.1176],
          [0.1176, 0.1176, 0.1176,  ..., 0.1176, 0.1176, 0.1176],
          [0.1176, 0.1176, 0.1176,  ..., 0.1176, 0.1176, 0.1176],
          ...,
          [0.0314, 0.0314, 0.0314,  ..., 0.0392, 0.0392, 0.0353],
          [0.0549, 0.0549, 0.0510,  ..., 0.0549, 0.0549, 0.0549],
          [0.0431, 0.0431, 0.0431,  ..., 0.0431, 0.0431, 0.0431]]]])
tensor([[[[0.2980, 0.2980, 0.2980,  ..., 0.2980, 0.2980, 0.2980],
          [0.2980, 0.2980, 0.2980,  ..., 0.2980, 0.2980, 0.2980],
          [0.3020, 0.3020, 0.3020,  ..., 0.3020, 0.2980, 0.3020],
          ...,
          [0.0902, 0.0902, 0.0902,  ..., 0.0824, 0.0902, 0.0941],
          [0.1137, 0.1098, 0.1059,  ..., 0.1176, 0.1176, 0.1137],
          [0.0824, 0.0824, 0.0824,  ..., 0.0863, 0.0863, 0.0863]],

         [[0.2667, 0.2667, 0.2667,  ..., 0.2667, 0.2667, 0.2667],
          [0.2667, 0.2667, 0.2667,  ..., 0.2667, 0.2627, 0.2667],
          [0.2667, 0.2667, 0.2667,  ..., 0.2667, 0.2667, 0.2667],
          ...,
          [0.0745, 0.0706, 0.0745,  ..., 0.0588, 0.0706, 0.0745],
          [0.1020, 0.0980, 0.0941,  ..., 0.1059, 0.1059, 0.1020],
          [0.0745, 0.0706, 0.0706,  ..., 0.0745, 0.0745, 0.0745]],

         [[0.2118, 0.2118, 0.2118,  ..., 0.2118, 0.2118, 0.2118],
          [0.2157, 0.2157, 0.2157,  ..., 0.2157, 0.2157, 0.2157],
          [0.2157, 0.2157, 0.2157,  ..., 0.2157, 0.2157, 0.2157],
          ...,
          [0.0627, 0.0588, 0.0588,  ..., 0.0549, 0.0588, 0.0667],
          [0.0902, 0.0863, 0.0824,  ..., 0.0941, 0.0941, 0.0902],
          [0.0706, 0.0667, 0.0667,  ..., 0.0706, 0.0706, 0.0706]]],


        [[[0.3333, 0.3333, 0.3333,  ..., 0.3333, 0.3333, 0.3333],
          [0.3373, 0.3412, 0.3412,  ..., 0.3412, 0.3412, 0.3373],
          [0.3412, 0.3412, 0.3412,  ..., 0.3412, 0.3412, 0.3412],
          ...,
          [0.0902, 0.0902, 0.0902,  ..., 0.0980, 0.0980, 0.0941],
          [0.0863, 0.0824, 0.0824,  ..., 0.0863, 0.0863, 0.0863],
          [0.0902, 0.0941, 0.0941,  ..., 0.0902, 0.0902, 0.0902]],

         [[0.2588, 0.2588, 0.2588,  ..., 0.2588, 0.2588, 0.2588],
          [0.2627, 0.2667, 0.2667,  ..., 0.2667, 0.2667, 0.2627],
          [0.2667, 0.2667, 0.2667,  ..., 0.2667, 0.2667, 0.2667],
          ...,
          [0.0510, 0.0471, 0.0431,  ..., 0.0588, 0.0510, 0.0510],
          [0.0510, 0.0510, 0.0510,  ..., 0.0549, 0.0549, 0.0510],
          [0.0588, 0.0588, 0.0627,  ..., 0.0588, 0.0588, 0.0588]],

         [[0.1059, 0.1059, 0.1059,  ..., 0.1059, 0.1059, 0.1059],
          [0.1098, 0.1098, 0.1098,  ..., 0.1098, 0.1098, 0.1098],
          [0.1098, 0.1098, 0.1137,  ..., 0.1137, 0.1098, 0.1098],
          ...,
          [0.0235, 0.0235, 0.0235,  ..., 0.0275, 0.0275, 0.0235],
          [0.0353, 0.0314, 0.0314,  ..., 0.0353, 0.0353, 0.0353],
          [0.0392, 0.0392, 0.0392,  ..., 0.0392, 0.0392, 0.0392]]],


        [[[0.5529, 0.5569, 0.5569,  ..., 0.5529, 0.5529, 0.5529],
          [0.5765, 0.5765, 0.5765,  ..., 0.5765, 0.5765, 0.5765],
          [0.5765, 0.5765, 0.5765,  ..., 0.5765, 0.5765, 0.5765],
          ...,
          [0.1451, 0.1412, 0.1412,  ..., 0.1333, 0.1373, 0.1412],
          [0.1490, 0.1490, 0.1529,  ..., 0.1490, 0.1490, 0.1490],
          [0.1412, 0.1412, 0.1412,  ..., 0.1412, 0.1412, 0.1412]],

         [[0.5098, 0.5137, 0.5137,  ..., 0.5098, 0.5098, 0.5098],
          [0.5294, 0.5294, 0.5294,  ..., 0.5294, 0.5294, 0.5294],
          [0.5294, 0.5333, 0.5333,  ..., 0.5294, 0.5294, 0.5294],
          ...,
          [0.0863, 0.0863, 0.0863,  ..., 0.0784, 0.0824, 0.0824],
          [0.0902, 0.0941, 0.0941,  ..., 0.0941, 0.0902, 0.0902],
          [0.0824, 0.0824, 0.0824,  ..., 0.0863, 0.0863, 0.0863]],

         [[0.4392, 0.4392, 0.4392,  ..., 0.4392, 0.4392, 0.4392],
          [0.4627, 0.4627, 0.4627,  ..., 0.4627, 0.4627, 0.4627],
          [0.4706, 0.4706, 0.4706,  ..., 0.4667, 0.4706, 0.4706],
          ...,
          [0.0510, 0.0510, 0.0510,  ..., 0.0431, 0.0471, 0.0471],
          [0.0549, 0.0549, 0.0549,  ..., 0.0510, 0.0510, 0.0549],
          [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588]]],


        ...,


        [[[0.2902, 0.2902, 0.2902,  ..., 0.2902, 0.2902, 0.2902],
          [0.2863, 0.2863, 0.2863,  ..., 0.2863, 0.2863, 0.2863],
          [0.2863, 0.2863, 0.2863,  ..., 0.2824, 0.2863, 0.2863],
          ...,
          [0.0392, 0.0431, 0.0431,  ..., 0.0431, 0.0392, 0.0392],
          [0.0392, 0.0392, 0.0392,  ..., 0.0431, 0.0392, 0.0392],
          [0.0353, 0.0392, 0.0392,  ..., 0.0392, 0.0353, 0.0353]],

         [[0.2588, 0.2588, 0.2588,  ..., 0.2588, 0.2588, 0.2588],
          [0.2588, 0.2588, 0.2588,  ..., 0.2588, 0.2588, 0.2588],
          [0.2588, 0.2588, 0.2588,  ..., 0.2549, 0.2588, 0.2588],
          ...,
          [0.0196, 0.0196, 0.0196,  ..., 0.0196, 0.0196, 0.0196],
          [0.0196, 0.0196, 0.0196,  ..., 0.0196, 0.0196, 0.0196],
          [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157]],

         [[0.2235, 0.2235, 0.2235,  ..., 0.2235, 0.2235, 0.2235],
          [0.2196, 0.2196, 0.2196,  ..., 0.2196, 0.2196, 0.2196],
          [0.2196, 0.2196, 0.2196,  ..., 0.2196, 0.2196, 0.2196],
          ...,
          [0.0157, 0.0196, 0.0196,  ..., 0.0196, 0.0157, 0.0157],
          [0.0157, 0.0157, 0.0157,  ..., 0.0196, 0.0157, 0.0157],
          [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118]]],


        [[[0.3255, 0.3255, 0.3255,  ..., 0.3294, 0.3294, 0.3255],
          [0.3255, 0.3255, 0.3255,  ..., 0.3255, 0.3255, 0.3255],
          [0.3255, 0.3255, 0.3255,  ..., 0.3255, 0.3255, 0.3255],
          ...,
          [0.0510, 0.0510, 0.0510,  ..., 0.0549, 0.0510, 0.0510],
          [0.0510, 0.0510, 0.0510,  ..., 0.0510, 0.0510, 0.0510],
          [0.0510, 0.0510, 0.0510,  ..., 0.0510, 0.0510, 0.0510]],

         [[0.3176, 0.3176, 0.3176,  ..., 0.3216, 0.3216, 0.3176],
          [0.3176, 0.3176, 0.3176,  ..., 0.3176, 0.3176, 0.3176],
          [0.3176, 0.3176, 0.3176,  ..., 0.3137, 0.3176, 0.3137],
          ...,
          [0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0314, 0.0314],
          [0.0275, 0.0275, 0.0275,  ..., 0.0314, 0.0275, 0.0275],
          [0.0235, 0.0235, 0.0235,  ..., 0.0235, 0.0235, 0.0235]],

         [[0.2941, 0.2941, 0.2941,  ..., 0.2980, 0.2980, 0.2941],
          [0.2941, 0.2941, 0.2941,  ..., 0.2941, 0.2941, 0.2941],
          [0.2941, 0.2941, 0.2941,  ..., 0.2941, 0.2941, 0.2941],
          ...,
          [0.0275, 0.0235, 0.0275,  ..., 0.0275, 0.0275, 0.0275],
          [0.0275, 0.0275, 0.0275,  ..., 0.0275, 0.0275, 0.0275],
          [0.0235, 0.0235, 0.0235,  ..., 0.0235, 0.0235, 0.0235]]],


        [[[0.7765, 0.7765, 0.7765,  ..., 0.7765, 0.7765, 0.7765],
          [0.7725, 0.7686, 0.7686,  ..., 0.7725, 0.7686, 0.7725],
          [0.7647, 0.7608, 0.7569,  ..., 0.7686, 0.7647, 0.7647],
          ...,
          [0.3647, 0.3686, 0.3765,  ..., 0.3647, 0.3647, 0.3647],
          [0.3686, 0.3686, 0.3686,  ..., 0.3686, 0.3686, 0.3686],
          [0.3765, 0.3765, 0.3765,  ..., 0.3804, 0.3765, 0.3765]],

         [[0.6980, 0.6980, 0.6980,  ..., 0.6980, 0.6980, 0.6980],
          [0.6941, 0.6902, 0.6902,  ..., 0.6941, 0.6941, 0.6941],
          [0.6863, 0.6824, 0.6824,  ..., 0.6902, 0.6863, 0.6863],
          ...,
          [0.2627, 0.2627, 0.2627,  ..., 0.2627, 0.2627, 0.2627],
          [0.2706, 0.2706, 0.2706,  ..., 0.2706, 0.2706, 0.2706],
          [0.2706, 0.2706, 0.2667,  ..., 0.2706, 0.2745, 0.2745]],

         [[0.6235, 0.6235, 0.6235,  ..., 0.6235, 0.6235, 0.6235],
          [0.6275, 0.6275, 0.6235,  ..., 0.6235, 0.6235, 0.6275],
          [0.6275, 0.6235, 0.6235,  ..., 0.6235, 0.6235, 0.6235],
          ...,
          [0.1412, 0.1412, 0.1412,  ..., 0.1451, 0.1451, 0.1412],
          [0.1412, 0.1412, 0.1373,  ..., 0.1373, 0.1373, 0.1373],
          [0.1412, 0.1412, 0.1373,  ..., 0.1412, 0.1412, 0.1412]]]])
tensor([[[[0.3098, 0.3137, 0.3137,  ..., 0.3137, 0.3098, 0.3098],
          [0.3098, 0.3098, 0.3098,  ..., 0.3098, 0.3098, 0.3137],
          [0.3137, 0.3098, 0.3098,  ..., 0.3098, 0.3098, 0.3098],
          ...,
          [0.0863, 0.0824, 0.0824,  ..., 0.0902, 0.0863, 0.0863],
          [0.0863, 0.0863, 0.0863,  ..., 0.0824, 0.0863, 0.0863],
          [0.0863, 0.0863, 0.0863,  ..., 0.0902, 0.0902, 0.0863]],

         [[0.2549, 0.2549, 0.2549,  ..., 0.2549, 0.2549, 0.2549],
          [0.2588, 0.2588, 0.2588,  ..., 0.2588, 0.2588, 0.2627],
          [0.2588, 0.2588, 0.2588,  ..., 0.2588, 0.2588, 0.2588],
          ...,
          [0.0627, 0.0627, 0.0588,  ..., 0.0667, 0.0667, 0.0667],
          [0.0588, 0.0588, 0.0588,  ..., 0.0549, 0.0588, 0.0588],
          [0.0588, 0.0588, 0.0588,  ..., 0.0667, 0.0627, 0.0588]],

         [[0.1882, 0.1882, 0.1882,  ..., 0.1882, 0.1882, 0.1882],
          [0.1882, 0.1882, 0.1882,  ..., 0.1882, 0.1882, 0.1882],
          [0.1882, 0.1882, 0.1882,  ..., 0.1882, 0.1882, 0.1882],
          ...,
          [0.0667, 0.0627, 0.0588,  ..., 0.0627, 0.0627, 0.0627],
          [0.0588, 0.0627, 0.0588,  ..., 0.0627, 0.0627, 0.0588],
          [0.0667, 0.0667, 0.0667,  ..., 0.0667, 0.0667, 0.0667]]],


        [[[0.1333, 0.1333, 0.1333,  ..., 0.1333, 0.1333, 0.1333],
          [0.1333, 0.1333, 0.1373,  ..., 0.1373, 0.1373, 0.1333],
          [0.1333, 0.1333, 0.1373,  ..., 0.1333, 0.1333, 0.1333],
          ...,
          [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],
          [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118],
          [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157]],

         [[0.1137, 0.1137, 0.1137,  ..., 0.1137, 0.1137, 0.1137],
          [0.1137, 0.1137, 0.1137,  ..., 0.1137, 0.1137, 0.1137],
          [0.1137, 0.1137, 0.1137,  ..., 0.1137, 0.1137, 0.1137],
          ...,
          [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],
          [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],
          [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118]],

         [[0.0745, 0.0745, 0.0745,  ..., 0.0745, 0.0745, 0.0745],
          [0.0745, 0.0745, 0.0745,  ..., 0.0745, 0.0745, 0.0745],
          [0.0745, 0.0745, 0.0784,  ..., 0.0745, 0.0745, 0.0745],
          ...,
          [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0039],
          [0.0078, 0.0039, 0.0078,  ..., 0.0078, 0.0078, 0.0078],
          [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0118]]],


        [[[0.4471, 0.4471, 0.4471,  ..., 0.4431, 0.4471, 0.4471],
          [0.4431, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],
          [0.4431, 0.4431, 0.4471,  ..., 0.4431, 0.4431, 0.4431],
          ...,
          [0.3922, 0.3882, 0.3882,  ..., 0.3961, 0.3922, 0.3922],
          [0.2510, 0.2431, 0.2275,  ..., 0.2863, 0.2784, 0.2627],
          [0.0902, 0.0902, 0.0902,  ..., 0.1020, 0.0980, 0.0941]],

         [[0.3843, 0.3843, 0.3843,  ..., 0.3804, 0.3843, 0.3843],
          [0.3804, 0.3843, 0.3843,  ..., 0.3843, 0.3843, 0.3843],
          [0.3804, 0.3804, 0.3843,  ..., 0.3804, 0.3804, 0.3804],
          ...,
          [0.2980, 0.2941, 0.2941,  ..., 0.3020, 0.2980, 0.2980],
          [0.2000, 0.1961, 0.1804,  ..., 0.2314, 0.2235, 0.2118],
          [0.0431, 0.0353, 0.0353,  ..., 0.0549, 0.0510, 0.0471]],

         [[0.3373, 0.3373, 0.3373,  ..., 0.3333, 0.3373, 0.3373],
          [0.3333, 0.3373, 0.3373,  ..., 0.3373, 0.3373, 0.3373],
          [0.3333, 0.3333, 0.3373,  ..., 0.3333, 0.3333, 0.3333],
          ...,
          [0.2510, 0.2510, 0.2510,  ..., 0.2549, 0.2510, 0.2549],
          [0.1804, 0.1765, 0.1686,  ..., 0.2000, 0.1922, 0.1882],
          [0.0627, 0.0627, 0.0588,  ..., 0.0745, 0.0706, 0.0706]]],


        ...,


        [[[0.3608, 0.3608, 0.3608,  ..., 0.3608, 0.3608, 0.3608],
          [0.3569, 0.3569, 0.3608,  ..., 0.3569, 0.3569, 0.3569],
          [0.3569, 0.3569, 0.3569,  ..., 0.3608, 0.3608, 0.3608],
          ...,
          [0.1020, 0.1020, 0.1020,  ..., 0.1059, 0.1059, 0.1020],
          [0.0941, 0.0941, 0.0941,  ..., 0.0902, 0.0902, 0.0902],
          [0.1020, 0.1020, 0.1020,  ..., 0.0980, 0.1020, 0.1020]],

         [[0.3255, 0.3255, 0.3294,  ..., 0.3255, 0.3255, 0.3255],
          [0.3216, 0.3216, 0.3216,  ..., 0.3216, 0.3216, 0.3216],
          [0.3176, 0.3176, 0.3176,  ..., 0.3176, 0.3176, 0.3216],
          ...,
          [0.0588, 0.0549, 0.0549,  ..., 0.0588, 0.0588, 0.0549],
          [0.0471, 0.0471, 0.0471,  ..., 0.0431, 0.0431, 0.0431],
          [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588]],

         [[0.2980, 0.3020, 0.3020,  ..., 0.2980, 0.2980, 0.2980],
          [0.2863, 0.2863, 0.2902,  ..., 0.2863, 0.2863, 0.2863],
          [0.2824, 0.2824, 0.2824,  ..., 0.2824, 0.2824, 0.2824],
          ...,
          [0.0392, 0.0392, 0.0392,  ..., 0.0431, 0.0431, 0.0392],
          [0.0353, 0.0353, 0.0353,  ..., 0.0314, 0.0314, 0.0353],
          [0.0471, 0.0471, 0.0510,  ..., 0.0510, 0.0471, 0.0510]]],


        [[[0.3020, 0.3020, 0.3020,  ..., 0.3020, 0.3020, 0.3020],
          [0.3020, 0.3020, 0.3020,  ..., 0.2980, 0.3020, 0.3020],
          [0.3020, 0.3020, 0.3020,  ..., 0.2980, 0.2980, 0.2980],
          ...,
          [0.0902, 0.0902, 0.0902,  ..., 0.0902, 0.0902, 0.0902],
          [0.0902, 0.0941, 0.0941,  ..., 0.0902, 0.0902, 0.0902],
          [0.0980, 0.0980, 0.0980,  ..., 0.0980, 0.0980, 0.0980]],

         [[0.2941, 0.2941, 0.2941,  ..., 0.2941, 0.2941, 0.2941],
          [0.2941, 0.2941, 0.2941,  ..., 0.2902, 0.2941, 0.2941],
          [0.2980, 0.2980, 0.2980,  ..., 0.2941, 0.2941, 0.2941],
          ...,
          [0.0667, 0.0667, 0.0667,  ..., 0.0667, 0.0667, 0.0667],
          [0.0706, 0.0706, 0.0745,  ..., 0.0667, 0.0667, 0.0667],
          [0.0863, 0.0863, 0.0863,  ..., 0.0824, 0.0824, 0.0824]],

         [[0.2902, 0.2902, 0.2902,  ..., 0.2902, 0.2902, 0.2902],
          [0.2902, 0.2902, 0.2902,  ..., 0.2863, 0.2902, 0.2902],
          [0.2902, 0.2902, 0.2902,  ..., 0.2902, 0.2902, 0.2902],
          ...,
          [0.0431, 0.0471, 0.0431,  ..., 0.0471, 0.0471, 0.0431],
          [0.0510, 0.0549, 0.0549,  ..., 0.0471, 0.0471, 0.0471],
          [0.0745, 0.0745, 0.0745,  ..., 0.0706, 0.0706, 0.0745]]],


        [[[0.5294, 0.5255, 0.5294,  ..., 0.5294, 0.5294, 0.5255],
          [0.5294, 0.5255, 0.5255,  ..., 0.5255, 0.5255, 0.5255],
          [0.5176, 0.5176, 0.5216,  ..., 0.5176, 0.5176, 0.5176],
          ...,
          [0.0824, 0.0824, 0.0824,  ..., 0.0824, 0.0824, 0.0824],
          [0.0902, 0.0902, 0.0902,  ..., 0.0902, 0.0941, 0.0902],
          [0.0784, 0.0784, 0.0824,  ..., 0.0824, 0.0824, 0.0784]],

         [[0.4431, 0.4392, 0.4431,  ..., 0.4431, 0.4431, 0.4392],
          [0.4431, 0.4431, 0.4431,  ..., 0.4431, 0.4431, 0.4431],
          [0.4431, 0.4392, 0.4392,  ..., 0.4392, 0.4392, 0.4392],
          ...,
          [0.0588, 0.0588, 0.0549,  ..., 0.0510, 0.0510, 0.0549],
          [0.0549, 0.0549, 0.0549,  ..., 0.0549, 0.0588, 0.0549],
          [0.0392, 0.0392, 0.0392,  ..., 0.0431, 0.0431, 0.0392]],

         [[0.2941, 0.2941, 0.2980,  ..., 0.2980, 0.2980, 0.2941],
          [0.2902, 0.2902, 0.2902,  ..., 0.2902, 0.2902, 0.2902],
          [0.2863, 0.2863, 0.2863,  ..., 0.2863, 0.2863, 0.2863],
          ...,
          [0.0549, 0.0549, 0.0510,  ..., 0.0588, 0.0549, 0.0549],
          [0.0431, 0.0471, 0.0471,  ..., 0.0471, 0.0471, 0.0471],
          [0.0314, 0.0314, 0.0353,  ..., 0.0353, 0.0353, 0.0314]]]])
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/classifier_resnet50.py", line 441, in <module>
    for i, data in enumerate(label_dataloader_train, 0):
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 681, in __next__
    data = self._next_data()
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1359, in _next_data
    idx, data = self._get_data()
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1325, in _get_data
    success, data = self._try_get_data()
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1163, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt
alpha set
parameters: 
batch_size = 64
shuffle_train = True
num_workers = 8
epoch = 50
augmentation = numpy.roll + colorJitter
Start training, 2023-07-06 04:49:26.540385
torch.Size([64, 3, 128, 256])
torch.Size([64, 3, 128, 256])
torch.Size([64, 3, 128, 256])
torch.Size([64, 3, 128, 256])
torch.Size([64, 3, 128, 256])
torch.Size([64, 3, 128, 256])
torch.Size([64, 3, 128, 256])
torch.Size([64, 3, 128, 256])
torch.Size([64, 3, 128, 256])
torch.Size([64, 3, 128, 256])
torch.Size([64, 3, 128, 256])
torch.Size([64, 3, 128, 256])
torch.Size([64, 3, 128, 256])
torch.Size([64, 3, 128, 256])
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/classifier_resnet50.py", line 453, in <module>
    optimizer.step()
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/optim/optimizer.py", line 113, in wrapper
    return func(*args, **kwargs)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/optim/sgd.py", line 146, in step
    sgd(params_with_grad,
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/optim/sgd.py", line 197, in sgd
    func(params,
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/optim/sgd.py", line 241, in _single_tensor_sgd
    param.add_(d_p, alpha=alpha)
KeyboardInterrupt
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 8
epoch = 20

Start training, 2023-07-06 04:50:08.864037
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 218, in <module>
    print(data[0].size())
AttributeError: 'list' object has no attribute 'size'
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 8
epoch = 20

Start training, 2023-07-06 04:50:42.085121
40
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 219, in <module>
    inputs, labels = data[0].cuda(), data[1].cuda()
AttributeError: 'list' object has no attribute 'cuda'
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 8
epoch = 20

Start training, 2023-07-06 04:51:35.161747
40
torch.Size([1, 3, 128, 256])
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 220, in <module>
    inputs, labels = data[0].cuda(), data[1].cuda()
AttributeError: 'list' object has no attribute 'cuda'
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 8
epoch = 20

Start training, 2023-07-06 04:58:36.069996
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 218, in <module>
    temp = torch.tensor([x.tolist[0]] for x in data[0])
RuntimeError: Could not infer dtype of generator
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 8
epoch = 20

Start training, 2023-07-06 05:00:05.367990
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 218, in <module>
    temp = torch.tensor(list(x.tolist[0]) for x in data[0])
RuntimeError: Could not infer dtype of generator
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 8
epoch = 20

Start training, 2023-07-06 05:02:09.446993
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 218, in <module>
    temp = torch.tensor(x.tolist[0] for x in data[0])
RuntimeError: Could not infer dtype of generator
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 8
epoch = 20

Start training, 2023-07-06 05:02:53.926505
<generator object <genexpr> at 0x7feb83c68740>
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 220, in <module>
    print(temp.size())
NameError: name 'temp' is not defined
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 8
epoch = 20

Start training, 2023-07-06 05:04:44.081579
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 220, in <module>
    temp += x.tolist[0]
TypeError: 'builtin_function_or_method' object is not subscriptable
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 8
epoch = 20

Start training, 2023-07-06 05:05:21.434028
torch.Size([120, 128, 256])
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 224, in <module>
    inputs, labels = data[0].cuda(), data[1].cuda()
AttributeError: 'list' object has no attribute 'cuda'
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 8
epoch = 20

Start training, 2023-07-06 05:05:52.473520
torch.Size([40, 3, 128, 256])
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 224, in <module>
    inputs, labels = data[0].cuda(), data[1].cuda()
AttributeError: 'list' object has no attribute 'cuda'
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 8
epoch = 20

Start training, 2023-07-06 05:07:13.142781
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 223, in <module>
    temp2 += x.tolist()
AttributeError: 'tuple' object has no attribute 'tolist'
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 8
epoch = 20

Start training, 2023-07-06 05:08:05.438398
torch.Size([40, 3, 128, 256])
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 228, in <module>
    inputs, labels = temp.cuda(), data[1].cuda()
AttributeError: 'list' object has no attribute 'cuda'
alpha set
parameters: 
batch_size = 64
shuffle_train = True
num_workers = 8
epoch = 50
augmentation = numpy.roll + colorJitter
Start training, 2023-07-06 05:08:33.086798
tensor([ 0,  5,  2,  1, 11,  5,  0, 15,  3,  8, 17, 11,  0,  7,  4,  4,  1,  7,
         2,  5,  7,  0,  4,  1,  8,  5,  8,  1, 16,  1,  0,  3,  5,  4,  2,  5,
         8,  0,  1,  2,  1,  6,  3,  8,  4,  6,  0,  0,  3,  0,  3,  4,  2,  2,
         1,  8,  8,  2,  5,  2,  2,  6,  0,  8])
tensor([ 6,  2,  5,  0,  0, 10,  5,  0,  3,  3,  2,  4,  5,  0,  2,  2,  2,  3,
        11, 20,  0, 14,  8,  0,  0,  8,  2, 22,  0,  2, 10,  8,  5,  4,  5,  3,
         1,  2,  3,  9,  2,  4,  1,  1,  1,  2,  1,  6,  5,  2,  2,  0,  0,  0,
        22,  5,  6,  6,  2,  3,  2,  1,  6,  2])
tensor([ 5,  0,  4,  5,  4,  0,  1,  5,  1,  2,  0,  2,  8,  0,  0,  1,  1,  0,
         8,  3,  1,  0,  5,  2,  1,  2,  2,  1,  5,  7,  0,  8,  2,  2,  2,  1,
        10,  2,  1,  9,  8,  2,  8,  0,  3,  3,  5, 17,  6, 12,  2,  3,  2,  1,
         2,  2,  2,  1, 22,  2,  2,  2, 22,  1])
tensor([ 3,  7,  3,  8,  2, 17,  0,  4,  1,  4,  2,  8,  2,  3,  8, 11,  2,  4,
         8,  2,  3,  5,  1,  2,  2,  0,  2,  2, 17,  1,  8,  3,  0,  4,  2,  0,
         1, 22,  6,  2,  2,  8,  7,  7,  0, 22,  2,  8,  1,  6,  7,  2,  1, 22,
         8,  6,  6,  6,  2,  3,  2,  2,  3,  8])
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/classifier_resnet50.py", line 452, in <module>
    loss.backward()
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 8
epoch = 20

Start training, 2023-07-06 05:09:21.666347
[('0102',), ('0102',), ('0102',), ('0103',), ('0104',), ('0104',), ('0105',), ('0105',), ('0106',), ('0107',), ('0101',), ('0101',), ('0101',), ('0203',), ('0205',), ('0205',), ('0206',), ('0206',), ('0204',), ('0204',), ('0202',), ('0202',), ('0201',), ('0309',), ('0302',), ('0302',), ('0303',), ('0304',), ('0304',), ('0304',), ('0305',), ('0305',), ('0306',), ('0306',), ('0307',), ('0308',), ('0308',), ('0310',), ('0310',), ('0301',)]
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 224, in <module>
    temp2 += x.tolist()
AttributeError: 'tuple' object has no attribute 'tolist'
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 8
epoch = 20

Start training, 2023-07-06 05:10:01.505733
[('0102',), ('0102',), ('0102',), ('0103',), ('0104',), ('0104',), ('0105',), ('0105',), ('0106',), ('0107',), ('0101',), ('0101',), ('0101',), ('0203',), ('0205',), ('0205',), ('0206',), ('0206',), ('0204',), ('0204',), ('0202',), ('0202',), ('0201',), ('0309',), ('0302',), ('0302',), ('0303',), ('0304',), ('0304',), ('0304',), ('0305',), ('0305',), ('0306',), ('0306',), ('0307',), ('0308',), ('0308',), ('0310',), ('0310',), ('0301',)]
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 224, in <module>
    temp2 += int(x[0])
TypeError: 'int' object is not iterable
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 8
epoch = 20

Start training, 2023-07-06 05:10:52.994933
[('0102',), ('0102',), ('0102',), ('0103',), ('0104',), ('0104',), ('0105',), ('0105',), ('0106',), ('0107',), ('0101',), ('0101',), ('0101',), ('0203',), ('0205',), ('0205',), ('0206',), ('0206',), ('0204',), ('0204',), ('0202',), ('0202',), ('0201',), ('0309',), ('0302',), ('0302',), ('0303',), ('0304',), ('0304',), ('0304',), ('0305',), ('0305',), ('0306',), ('0306',), ('0307',), ('0308',), ('0308',), ('0310',), ('0310',), ('0301',)]
['0', '1', '0', '2', '0', '1', '0', '2', '0', '1', '0', '2', '0', '1', '0', '3', '0', '1', '0', '4', '0', '1', '0', '4', '0', '1', '0', '5', '0', '1', '0', '5', '0', '1', '0', '6', '0', '1', '0', '7', '0', '1', '0', '1', '0', '1', '0', '1', '0', '1', '0', '1', '0', '2', '0', '3', '0', '2', '0', '5', '0', '2', '0', '5', '0', '2', '0', '6', '0', '2', '0', '6', '0', '2', '0', '4', '0', '2', '0', '4', '0', '2', '0', '2', '0', '2', '0', '2', '0', '2', '0', '1', '0', '3', '0', '9', '0', '3', '0', '2', '0', '3', '0', '2', '0', '3', '0', '3', '0', '3', '0', '4', '0', '3', '0', '4', '0', '3', '0', '4', '0', '3', '0', '5', '0', '3', '0', '5', '0', '3', '0', '6', '0', '3', '0', '6', '0', '3', '0', '7', '0', '3', '0', '8', '0', '3', '0', '8', '0', '3', '1', '0', '0', '3', '1', '0', '0', '3', '0', '1']
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 8
epoch = 20

Start training, 2023-07-06 05:11:56.830095
[('0102',), ('0102',), ('0102',), ('0103',), ('0104',), ('0104',), ('0105',), ('0105',), ('0106',), ('0107',), ('0101',), ('0101',), ('0101',), ('0203',), ('0205',), ('0205',), ('0206',), ('0206',), ('0204',), ('0204',), ('0202',), ('0202',), ('0201',), ('0309',), ('0302',), ('0302',), ('0303',), ('0304',), ('0304',), ('0304',), ('0305',), ('0305',), ('0306',), ('0306',), ('0307',), ('0308',), ('0308',), ('0310',), ('0310',), ('0301',)]
('0102',)
('0102',)
('0102',)
('0103',)
('0104',)
('0104',)
('0105',)
('0105',)
('0106',)
('0107',)
('0101',)
('0101',)
('0101',)
('0203',)
('0205',)
('0205',)
('0206',)
('0206',)
('0204',)
('0204',)
('0202',)
('0202',)
('0201',)
('0309',)
('0302',)
('0302',)
('0303',)
('0304',)
('0304',)
('0304',)
('0305',)
('0305',)
('0306',)
('0306',)
('0307',)
('0308',)
('0308',)
('0310',)
('0310',)
('0301',)
['0', '1', '0', '2', '0', '1', '0', '2', '0', '1', '0', '2', '0', '1', '0', '3', '0', '1', '0', '4', '0', '1', '0', '4', '0', '1', '0', '5', '0', '1', '0', '5', '0', '1', '0', '6', '0', '1', '0', '7', '0', '1', '0', '1', '0', '1', '0', '1', '0', '1', '0', '1', '0', '2', '0', '3', '0', '2', '0', '5', '0', '2', '0', '5', '0', '2', '0', '6', '0', '2', '0', '6', '0', '2', '0', '4', '0', '2', '0', '4', '0', '2', '0', '2', '0', '2', '0', '2', '0', '2', '0', '1', '0', '3', '0', '9', '0', '3', '0', '2', '0', '3', '0', '2', '0', '3', '0', '3', '0', '3', '0', '4', '0', '3', '0', '4', '0', '3', '0', '4', '0', '3', '0', '5', '0', '3', '0', '5', '0', '3', '0', '6', '0', '3', '0', '6', '0', '3', '0', '7', '0', '3', '0', '8', '0', '3', '0', '8', '0', '3', '1', '0', '0', '3', '1', '0', '0', '3', '0', '1']
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 8
epoch = 20

Start training, 2023-07-06 05:12:29.469021
[('0102',), ('0102',), ('0102',), ('0103',), ('0104',), ('0104',), ('0105',), ('0105',), ('0106',), ('0107',), ('0101',), ('0101',), ('0101',), ('0203',), ('0205',), ('0205',), ('0206',), ('0206',), ('0204',), ('0204',), ('0202',), ('0202',), ('0201',), ('0309',), ('0302',), ('0302',), ('0303',), ('0304',), ('0304',), ('0304',), ('0305',), ('0305',), ('0306',), ('0306',), ('0307',), ('0308',), ('0308',), ('0310',), ('0310',), ('0301',)]
0102
0102
0102
0103
0104
0104
0105
0105
0106
0107
0101
0101
0101
0203
0205
0205
0206
0206
0204
0204
0202
0202
0201
0309
0302
0302
0303
0304
0304
0304
0305
0305
0306
0306
0307
0308
0308
0310
0310
0301
['0', '1', '0', '2', '0', '1', '0', '2', '0', '1', '0', '2', '0', '1', '0', '3', '0', '1', '0', '4', '0', '1', '0', '4', '0', '1', '0', '5', '0', '1', '0', '5', '0', '1', '0', '6', '0', '1', '0', '7', '0', '1', '0', '1', '0', '1', '0', '1', '0', '1', '0', '1', '0', '2', '0', '3', '0', '2', '0', '5', '0', '2', '0', '5', '0', '2', '0', '6', '0', '2', '0', '6', '0', '2', '0', '4', '0', '2', '0', '4', '0', '2', '0', '2', '0', '2', '0', '2', '0', '2', '0', '1', '0', '3', '0', '9', '0', '3', '0', '2', '0', '3', '0', '2', '0', '3', '0', '3', '0', '3', '0', '4', '0', '3', '0', '4', '0', '3', '0', '4', '0', '3', '0', '5', '0', '3', '0', '5', '0', '3', '0', '6', '0', '3', '0', '6', '0', '3', '0', '7', '0', '3', '0', '8', '0', '3', '0', '8', '0', '3', '1', '0', '0', '3', '1', '0', '0', '3', '0', '1']
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 8
epoch = 20

Start training, 2023-07-06 05:12:56.203928
[('0102',), ('0102',), ('0102',), ('0103',), ('0104',), ('0104',), ('0105',), ('0105',), ('0106',), ('0107',), ('0101',), ('0101',), ('0101',), ('0203',), ('0205',), ('0205',), ('0206',), ('0206',), ('0204',), ('0204',), ('0202',), ('0202',), ('0201',), ('0309',), ('0302',), ('0302',), ('0303',), ('0304',), ('0304',), ('0304',), ('0305',), ('0305',), ('0306',), ('0306',), ('0307',), ('0308',), ('0308',), ('0310',), ('0310',), ('0301',)]
0102
0102
0102
0103
0104
0104
0105
0105
0106
0107
0101
0101
0101
0203
0205
0205
0206
0206
0204
0204
0202
0202
0201
0309
0302
0302
0303
0304
0304
0304
0305
0305
0306
0306
0307
0308
0308
0310
0310
0301
['0102', '0102', '0102', '0103', '0104', '0104', '0105', '0105', '0106', '0107', '0101', '0101', '0101', '0203', '0205', '0205', '0206', '0206', '0204', '0204', '0202', '0202', '0201', '0309', '0302', '0302', '0303', '0304', '0304', '0304', '0305', '0305', '0306', '0306', '0307', '0308', '0308', '0310', '0310', '0301']
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 8
epoch = 20

Start training, 2023-07-06 05:13:36.311373
[('0102',), ('0102',), ('0102',), ('0103',), ('0104',), ('0104',), ('0105',), ('0105',), ('0106',), ('0107',), ('0101',), ('0101',), ('0101',), ('0203',), ('0205',), ('0205',), ('0206',), ('0206',), ('0204',), ('0204',), ('0202',), ('0202',), ('0201',), ('0309',), ('0302',), ('0302',), ('0303',), ('0304',), ('0304',), ('0304',), ('0305',), ('0305',), ('0306',), ('0306',), ('0307',), ('0308',), ('0308',), ('0310',), ('0310',), ('0301',)]
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 230, in <module>
    temp2 = torch.tensor(temp2)
ValueError: too many dimensions 'str'
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 8
epoch = 20

Start training, 2023-07-06 05:14:09.027489
[('0102',), ('0102',), ('0102',), ('0103',), ('0104',), ('0104',), ('0105',), ('0105',), ('0106',), ('0107',), ('0101',), ('0101',), ('0101',), ('0203',), ('0205',), ('0205',), ('0206',), ('0206',), ('0204',), ('0204',), ('0202',), ('0202',), ('0201',), ('0309',), ('0302',), ('0302',), ('0303',), ('0304',), ('0304',), ('0304',), ('0305',), ('0305',), ('0306',), ('0306',), ('0307',), ('0308',), ('0308',), ('0310',), ('0310',), ('0301',)]
[102, 102, 102, 103, 104, 104, 105, 105, 106, 107, 101, 101, 101, 203, 205, 205, 206, 206, 204, 204, 202, 202, 201, 309, 302, 302, 303, 304, 304, 304, 305, 305, 306, 306, 307, 308, 308, 310, 310, 301]
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 238, in <module>
    outputs = net(inputs)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/tingwei/zillow_data/metric_learning.py", line 168, in forward
    x = self.conv1(x)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Given groups=1, weight of size [32, 1, 3, 3], expected input[40, 3, 128, 256] to have 1 channels, but got 3 channels instead
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 8
epoch = 20

Start training, 2023-07-06 05:17:48.782491
[102, 102, 102, 103, 104, 104, 105, 105, 106, 107, 101, 101, 101, 203, 205, 205, 206, 206, 204, 204, 202, 202, 201, 309, 302, 302, 303, 304, 304, 304, 305, 305, 306, 306, 307, 308, 308, 310, 310, 301]
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 240, in <module>
    outputs = net(inputs)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/tingwei/zillow_data/metric_learning.py", line 177, in forward
    x = self.fc1(x)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (40x632772 and 9216x300)
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 186, in <module>
    net = Net()
  File "/home/tingwei/zillow_data/metric_learning.py", line 167, in __init__
    self.fc1 = nn.Linear(632772, 70308)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 96, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: [enforce fail at alloc_cpu.cpp:73] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 177955735104 bytes. Error code 12 (Cannot allocate memory)
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 193, in <module>
    net.cuda()
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 689, in cuda
    return self._apply(lambda t: t.cuda(device))
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 689, in <lambda>
    return self._apply(lambda t: t.cuda(device))
RuntimeError: CUDA out of memory. Tried to allocate 18.42 GiB (GPU 0; 10.92 GiB total capacity; 81.00 KiB already allocated; 10.38 GiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 193, in <module>
    net.cuda()
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 689, in cuda
    return self._apply(lambda t: t.cuda(device))
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 689, in <lambda>
    return self._apply(lambda t: t.cuda(device))
RuntimeError: CUDA out of memory. Tried to allocate 18.42 GiB (GPU 0; 10.92 GiB total capacity; 81.00 KiB already allocated; 10.38 GiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 193, in <module>
    net.cuda()
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 689, in cuda
    return self._apply(lambda t: t.cuda(device))
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 689, in <lambda>
    return self._apply(lambda t: t.cuda(device))
RuntimeError: CUDA out of memory. Tried to allocate 18.42 GiB (GPU 0; 10.92 GiB total capacity; 3.50 KiB already allocated; 10.38 GiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 193, in <module>
    net.cuda()
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 689, in cuda
    return self._apply(lambda t: t.cuda(device))
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 689, in <lambda>
    return self._apply(lambda t: t.cuda(device))
RuntimeError: CUDA out of memory. Tried to allocate 18.42 GiB (GPU 0; 10.92 GiB total capacity; 3.50 KiB already allocated; 10.38 GiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 2
epoch = 20

Start training, 2023-07-06 14:10:32.687611
[102, 102, 102, 103, 104, 104, 105, 105, 106, 107, 101, 101, 101, 203, 205, 205, 206, 206, 204, 204, 202, 202, 201, 309, 302, 302, 303, 304, 304, 304, 305, 305, 306, 306, 307, 308, 308, 310, 310, 301]
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 246, in <module>
    outputs = net(inputs)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/tingwei/zillow_data/metric_learning.py", line 179, in forward
    x = self.fc1(x)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (40x216027 and 210924x7812)
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 2
epoch = 20

Start training, 2023-07-06 14:14:18.981234
[102, 102, 102, 103, 104, 104, 105, 105, 106, 107, 101, 101, 101, 203, 205, 205, 206, 206, 204, 204, 202, 202, 201, 309, 302, 302, 303, 304, 304, 304, 305, 305, 306, 306, 307, 308, 308, 310, 310, 301]
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 246, in <module>
    outputs = net(inputs)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/tingwei/zillow_data/metric_learning.py", line 183, in forward
    x = self.fc1(x)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (40x7812 and 216027x7812)
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 2
epoch = 20

Start training, 2023-07-06 14:14:52.406495
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 225, in <module>
    for i, data in enumerate(room_dataloader_train, 0):
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 681, in __next__
    data = self._next_data()
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1359, in _next_data
    idx, data = self._get_data()
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1325, in _get_data
    success, data = self._try_get_data()
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1163, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 2
epoch = 20

Start training, 2023-07-06 14:15:30.665089
[102, 102, 102, 103, 104, 104, 105, 105, 106, 107, 101, 101, 101, 203, 205, 205, 206, 206, 204, 204, 202, 202, 201, 309, 302, 302, 303, 304, 304, 304, 305, 305, 306, 306, 307, 308, 308, 310, 310, 301]
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 249, in <module>
    loss.backward()
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA out of memory. Tried to allocate 6.29 GiB (GPU 0; 10.92 GiB total capacity; 6.58 GiB already allocated; 3.71 GiB free; 6.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 2
epoch = 20

Start training, 2023-07-06 14:16:50.341746
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 246, in <module>
    outputs = net(inputs)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/tingwei/zillow_data/metric_learning.py", line 179, in forward
    x = self.fc1(x)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (40x144018 and 216027x7812)
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 2
epoch = 20

Start training, 2023-07-06 14:17:22.729158
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 250, in <module>
    optimizer.step()
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/optim/optimizer.py", line 113, in wrapper
    return func(*args, **kwargs)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/optim/sgd.py", line 146, in step
    sgd(params_with_grad,
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/optim/sgd.py", line 197, in sgd
    func(params,
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/optim/sgd.py", line 230, in _single_tensor_sgd
    buf = torch.clone(d_p).detach()
RuntimeError: CUDA out of memory. Tried to allocate 4.19 GiB (GPU 0; 10.92 GiB total capacity; 8.42 GiB already allocated; 1.81 GiB free; 8.51 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 2
epoch = 20

Start training, 2023-07-06 14:18:24.924061
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 249, in <module>
    loss.backward()
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA out of memory. Tried to allocate 2.15 GiB (GPU 0; 10.92 GiB total capacity; 6.69 GiB already allocated; 1.55 GiB free; 8.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 2
epoch = 20

Start training, 2023-07-06 14:19:57.128532
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 259, in <module>
    losses.append(running_loss)
AttributeError: module 'pytorch_metric_learning.losses' has no attribute 'append'
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 6
epoch = 20

Start training, 2023-07-06 14:22:19.092445
epoch # 1 done, 2023-07-06 14:39:42.441456
epoch # 2 done, 2023-07-06 14:57:04.138339
Traceback (most recent call last):
  File "/home/tingwei/zillow_data/metric_learning.py", line 277, in <module>
    images, labels = data[0].cuda(), data[1].cuda()
AttributeError: 'list' object has no attribute 'cuda'
parameters: 
batch_size = 1
shuffle_train = False
num_workers = 6
epoch = 20

Start training, 2023-07-06 15:53:12.043983
epoch # 1 done, 2023-07-06 16:09:20.709073
epoch # 2 done, 2023-07-06 16:25:38.504016
val # 2 done, 2023-07-06 16:32:06.948199
epoch # 3 done, 2023-07-06 16:48:20.439817
epoch # 4 done, 2023-07-06 17:04:48.177888
val # 4 done, 2023-07-06 17:11:10.406584
epoch # 5 done, 2023-07-06 17:27:31.210136
epoch # 6 done, 2023-07-06 17:43:52.519524
val # 6 done, 2023-07-06 17:50:15.822209
epoch # 7 done, 2023-07-06 18:06:32.928555
epoch # 8 done, 2023-07-06 18:22:55.921716
val # 8 done, 2023-07-06 18:29:18.052857
epoch # 9 done, 2023-07-06 18:45:41.490426
epoch # 10 done, 2023-07-06 19:02:05.527868
val # 10 done, 2023-07-06 19:08:29.997633
epoch # 11 done, 2023-07-06 19:24:38.063284
epoch # 12 done, 2023-07-06 19:40:59.108322
val # 12 done, 2023-07-06 19:47:22.877134
epoch # 13 done, 2023-07-06 20:03:40.221100
epoch # 14 done, 2023-07-06 20:20:50.981556
val # 14 done, 2023-07-06 20:27:23.406901
epoch # 15 done, 2023-07-06 20:43:38.609925
epoch # 16 done, 2023-07-06 20:55:02.125577
val # 16 done, 2023-07-06 21:01:05.100845
epoch # 17 done, 2023-07-06 21:16:51.489381
epoch # 18 done, 2023-07-06 21:25:10.118637
val # 18 done, 2023-07-06 21:31:13.139594
epoch # 19 done, 2023-07-06 21:43:00.090001
/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/tingwei/miniconda3/envs/Zillow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
epoch # 20 done, 2023-07-06 21:53:52.746373
val # 20 done, 2023-07-06 21:59:55.257417
              precision    recall  f1-score   support

           1       0.00      0.00      0.00        49
           2       0.00      0.00      0.00        51
           3       0.00      0.00      0.00        46
           4       0.00      0.00      0.00        42
           5       0.00      0.00      0.00        42
           6       0.00      0.00      0.00        32
           7       0.00      0.00      0.00        23
           8       0.00      0.00      0.00        23
           9       0.00      0.00      0.00        27
          10       0.00      0.00      0.00        14
          11       0.00      0.00      0.00        23
          12       0.00      0.00      0.00         4
          13       0.00      0.00      0.00         1
          14       0.00      0.00      0.00         1
          20       0.00      0.00      0.00         0
          21       0.00      0.00      0.00         0
          26       0.00      0.00      0.00         0
          27       0.00      0.00      0.00         0
          28       0.00      0.00      0.00         0
          29       0.00      0.00      0.00         0
          32       0.00      0.00      0.00         0
          34       0.00      0.00      0.00         0
          36       0.00      0.00      0.00         0
          37       0.00      0.00      0.00         0
          38       0.00      0.00      0.00         0
          41       0.00      0.00      0.00         0
          43       0.00      0.00      0.00         0
          44       0.00      0.00      0.00         0
          47       0.00      0.00      0.00         0
          49       0.00      0.00      0.00         0
          51       0.00      0.00      0.00         0
          55       0.00      0.00      0.00         0
          59       0.00      0.00      0.00         0
          63       0.00      0.00      0.00         0
          65       0.00      0.00      0.00         0
          71       0.00      0.00      0.00         0
          72       0.00      0.00      0.00         0
          76       0.00      0.00      0.00         0
          77       0.00      0.00      0.00         0
          80       0.00      0.00      0.00         0
          81       0.00      0.00      0.00         0
          84       0.00      0.00      0.00         0
          90       0.00      0.00      0.00         0
          92       0.00      0.00      0.00         0
          94       0.00      0.00      0.00         0
          96       0.00      0.00      0.00         0
          97       0.00      0.00      0.00         0
          99       0.00      0.00      0.00         0
         101       0.03      0.01      0.01       357
         102       0.00      0.00      0.00       321
         103       0.05      0.00      0.01       337
         104       0.05      0.02      0.02       307
         105       0.00      0.00      0.00       299
         106       0.00      0.00      0.00       292
         107       0.00      0.00      0.00       300
         108       0.00      0.00      0.00       292
         109       0.00      0.00      0.00       237
         110       0.00      0.00      0.00       227
         111       0.00      0.00      0.00       196
         112       0.00      0.00      0.00       179
         113       0.00      0.00      0.00       147
         114       0.00      0.00      0.00       140
         115       0.00      0.00      0.00       127
         116       0.00      0.00      0.00       114
         117       0.00      0.00      0.00        99
         118       0.00      0.00      0.00        68
         119       0.00      0.00      0.00        77
         120       0.00      0.00      0.00        58
         121       0.00      0.00      0.00        40
         122       0.00      0.00      0.00        25
         123       0.00      0.00      0.00        26
         124       0.00      0.00      0.00        19
         125       0.00      0.00      0.00        15
         126       0.00      0.00      0.00        13
         127       0.00      0.00      0.00         7
         128       0.00      0.00      0.00         8
         129       0.00      0.00      0.00        11
         130       0.00      0.00      0.00         2
         131       0.00      0.00      0.00         1
         133       0.00      0.00      0.00         0
         134       0.00      0.00      0.00         0
         141       0.00      0.00      0.00         0
         145       0.00      0.00      0.00         0
         152       0.00      0.00      0.00         0
         154       0.00      0.00      0.00         0
         163       0.00      0.00      0.00         0
         164       0.00      0.00      0.00         0
         167       0.00      0.00      0.00         0
         168       0.00      0.00      0.00         0
         172       0.00      0.00      0.00         0
         173       0.00      0.00      0.00         0
         175       0.00      0.00      0.00         0
         177       0.00      0.00      0.00         0
         181       0.00      0.00      0.00         0
         183       0.00      0.00      0.00         0
         190       0.00      0.00      0.00         0
         192       0.00      0.00      0.00         0
         193       0.00      0.00      0.00         0
         199       0.00      0.00      0.00         0
         201       0.00      0.00      0.00       163
         202       0.00      0.00      0.00       161
         203       0.00      0.00      0.00       168
         204       0.00      0.00      0.00       157
         205       0.00      0.00      0.00       147
         206       0.00      0.00      0.00       140
         207       0.00      0.00      0.00       147
         208       0.00      0.00      0.00       142
         209       0.00      0.00      0.00       128
         210       0.02      0.19      0.03       121
         211       0.00      0.00      0.00        91
         212       0.00      0.00      0.00        76
         213       0.00      0.00      0.00        63
         214       0.00      0.00      0.00        48
         215       0.00      0.00      0.00        32
         216       0.00      0.00      0.00        26
         217       0.00      0.00      0.00        19
         218       0.01      0.09      0.02        23
         219       0.00      0.00      0.00         4
         220       0.00      0.00      0.00         1
         225       0.00      0.00      0.00         0
         226       0.00      0.00      0.00         0
         230       0.00      0.00      0.00         0
         232       0.00      0.00      0.00         0
         233       0.00      0.00      0.00         0
         235       0.00      0.00      0.00         0
         237       0.00      0.00      0.00         0
         238       0.00      0.00      0.00         0
         239       0.00      0.00      0.00         0
         242       0.00      0.00      0.00         0
         243       0.00      0.00      0.00         0
         247       0.00      0.00      0.00         0
         248       0.00      0.00      0.00         0
         251       0.00      0.00      0.00         0
         252       0.00      0.00      0.00         0
         261       0.00      0.00      0.00         0
         266       0.00      0.00      0.00         0
         277       0.00      0.00      0.00         0
         279       0.00      0.00      0.00         0
         284       0.00      0.00      0.00         0
         285       0.00      0.00      0.00         0
         293       0.00      0.00      0.00         0
         294       0.00      0.00      0.00         0
         296       0.00      0.00      0.00         0
         298       0.00      0.00      0.00         0
         301       0.00      0.00      0.00         8
         302       0.00      0.00      0.00         9
         303       0.00      0.00      0.00         8
         304       0.00      0.00      0.00        12
         305       0.00      0.00      0.00         9
         306       0.00      0.00      0.00         9
         307       0.00      0.00      0.00         4
         308       0.00      0.00      0.00         4
         309       0.00      0.00      0.00        10
         310       0.00      0.00      0.00         6
         311       0.00      0.00      0.00         5
         312       0.00      0.00      0.00         4

    accuracy                           0.01      6664
   macro avg       0.00      0.00      0.00      6664
weighted avg       0.01      0.01      0.00      6664

Finished Training
